{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 02:32:29.313374: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout,Input\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy, BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import categorical_accuracy #AUC \n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from spektral.layers import GINConv,GCNConv #, GCSConv, GlobalAvgPool\n",
    "from spektral.utils.sparse import sp_matrix_to_sp_tensor\n",
    "from spektral.data import DisjointLoader, BatchLoader, Dataset, Graph\n",
    "from spektral.transforms.normalize_adj import NormalizeAdj\n",
    "from spektral.transforms.normalize_one import NormalizeOne\n",
    "from spektral.transforms.normalize_sphere import NormalizeSphere\n",
    "import gc\n",
    "import spektral.datasets\n",
    "from spektral.data import DisjointLoader, BatchLoader\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from spektral.models.gcn import GCN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import gc\n",
    "from spektral.data import Dataset, Graph\n",
    "\n",
    "# Custom dataset class\n",
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, graph_feature_files, ncol_files, **kwargs):\n",
    "        # Store the graph feature and ncol file lists\n",
    "        self.graph_feature_files = graph_feature_files\n",
    "        self.ncol_files = ncol_files\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def download(self):\n",
    "        pass\n",
    "\n",
    "    def read(self):\n",
    "        # We must return a list of Graph objects\n",
    "        output = []\n",
    "\n",
    "        # Iterate through graph_feature_files and ncol_files\n",
    "        for graph_feature_file, ncol_file in zip(self.graph_feature_files, self.ncol_files):\n",
    "            # Read graph features\n",
    "            x_tmp = pd.read_csv(graph_feature_file, sep=\",\", header=0)\n",
    "\n",
    "            # Read graph topology\n",
    "            a_tmp = pd.read_csv(ncol_file, sep=\" \", header=None, names=[\"source\", \"target\", \"weight\"])\n",
    "\n",
    "            # Create dictionaries that identify each node and label with an integer\n",
    "            class_idx = {name: idx for idx, name in enumerate(sorted(x_tmp[\"label\"].unique()))}\n",
    "            node_idx = {name: idx for idx, name in enumerate(sorted(x_tmp[\"node\"].unique()))}\n",
    "\n",
    "            # Change node names and label for their corresponding integer\n",
    "            x_tmp[\"node\"] = x_tmp[\"node\"].apply(lambda name: node_idx[name])\n",
    "            x_tmp[\"label\"] = x_tmp[\"label\"].apply(lambda value: class_idx[value])\n",
    "            a_tmp[\"source\"] = a_tmp[\"source\"].apply(lambda name: node_idx[name])\n",
    "            a_tmp[\"target\"] = a_tmp[\"target\"].apply(lambda name: node_idx[name])\n",
    "\n",
    "            # Node features:\n",
    "            x = x_tmp.sort_values(\"node\")[x_tmp.columns.difference([\"node\",\"label\"], sort=False)].to_numpy()\n",
    "            x = x.astype(np.float32)\n",
    "\n",
    "            # Create adjacency matrix from source, target, and weight\n",
    "            a_source = a_tmp[[\"source\"]].to_numpy().T\n",
    "            a_source = np.reshape(a_source, a_source.shape[-1])\n",
    "            a_target = a_tmp[[\"target\"]].to_numpy().T\n",
    "            a_target = np.reshape(a_target, a_target.shape[-1])\n",
    "            a_weight = a_tmp[[\"weight\"]].to_numpy().T\n",
    "            a_weight = np.reshape(a_weight, a_weight.shape[-1])\n",
    "\n",
    "            # Adjacency matrix:\n",
    "            #a = sparse.coo_matrix((a_weight, (a_source, a_target)), shape=(x.shape[0], x.shape[0]))\n",
    "            a = sparse.csr_matrix((a_weight, (a_source, a_target)), shape=(x.shape[0], x.shape[0]), dtype=np.float32)\n",
    "\n",
    "            # Label:\n",
    "            y = x_tmp.sort_values(\"node\")[\"label\"].to_numpy()\n",
    "            y.astype(np.int64)\n",
    "\n",
    "            # Create a Graph object and add it to the output list\n",
    "            output.append(Graph(x=x, a=a, y=y))\n",
    "\n",
    "            # Free memory\n",
    "            del x_tmp, x, a_tmp, a_source, a_target, a_weight, a, y\n",
    "            gc.collect()\n",
    "\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/CEPH/ctu13/ncol/capture20110810.binetflow.labels-positive-weights.ncol',\n",
       " '/mnt/CEPH/ctu13/ncol/capture20110811.binetflow.labels-positive-weights.ncol',\n",
       " '/mnt/CEPH/ctu13/ncol/capture20110812.binetflow.labels-positive-weights.ncol',\n",
       " '/mnt/CEPH/ctu13/ncol/capture20110815-2.binetflow.labels-positive-weights.ncol',\n",
       " '/mnt/CEPH/ctu13/ncol/capture20110815-3.binetflow.labels-positive-weights.ncol',\n",
       " '/mnt/CEPH/ctu13/ncol/capture20110815.binetflow.labels-positive-weights.ncol',\n",
       " '/mnt/CEPH/ctu13/ncol/capture20110816-2.binetflow.labels-positive-weights.ncol',\n",
       " '/mnt/CEPH/ctu13/ncol/capture20110816-3.binetflow.labels-positive-weights.ncol',\n",
       " '/mnt/CEPH/ctu13/ncol/capture20110816.binetflow.labels-positive-weights.ncol',\n",
       " '/mnt/CEPH/ctu13/ncol/capture20110817.binetflow.labels-positive-weights.ncol',\n",
       " '/mnt/CEPH/ctu13/ncol/capture20110818-2.binetflow.labels-positive-weights.ncol',\n",
       " '/mnt/CEPH/ctu13/ncol/capture20110818.binetflow.labels-positive-weights.ncol',\n",
       " '/mnt/CEPH/ctu13/ncol/capture20110819.binetflow.labels-positive-weights.ncol']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import os\n",
    "#os.listdir(\"\")\n",
    "import glob\n",
    "sorted(glob.glob(\"/mnt/CEPH/ctu13/features/*\"))\n",
    "sorted(glob.glob(\"/mnt/CEPH/ctu13/ncol/*\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of graph feature files and ncol files\n",
    "graph_feature_files = sorted(glob.glob(\"/mnt/CEPH/ctu13/features/*\"))\n",
    "ncol_files = sorted(glob.glob(\"/mnt/CEPH/ctu13/ncol/*\"))\n",
    "\n",
    "ncol_files\n",
    "# Instantiate the dataset\n",
    "dataset = MyDataset(graph_feature_files, ncol_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cap  1 : infected: 0  - normal: 605195  -- prop: 0.0\n",
      "cap  2 : infected: 0  - normal: 440574  -- prop: 0.0\n",
      "cap  3 : infected: 0  - normal: 430265  -- prop: 0.0\n",
      "cap  4 : infected: 0  - normal: 41399  -- prop: 0.0\n",
      "cap  5 : infected: 0  - normal: 313678  -- prop: 0.0\n",
      "cap  6 : infected: 0  - normal: 184901  -- prop: 0.0\n",
      "cap  7 : infected: 0  - normal: 37943  -- prop: 0.0\n",
      "cap  8 : infected: 0  - normal: 381450  -- prop: 0.0\n",
      "cap  9 : infected: 0  - normal: 106580  -- prop: 0.0\n",
      "cap  10 : infected: 0  - normal: 365794  -- prop: 0.0\n",
      "cap  11 : infected: 0  - normal: 41712  -- prop: 0.0\n",
      "cap  12 : infected: 0  - normal: 196686  -- prop: 0.0\n",
      "cap  13 : infected: 0  - normal: 93830  -- prop: 0.0\n"
     ]
    }
   ],
   "source": [
    "for j in range(13):\n",
    "    suma = 0\n",
    "    for i in range(dataset[j].n_nodes):\n",
    "        if all(dataset[j].y[i] == [0.,1.]):\n",
    "            suma+=1\n",
    "    print(\"cap \",j+1,\": infected:\",suma, \" - normal:\",dataset[j].n_nodes-suma, \" -- prop:\",suma/dataset[j].n_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(0.8 * len(dataset))\n",
    "dataset_train, dataset_test = dataset[:split], dataset[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<605195x605195 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 1234211 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train[0].a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "loader_train = DisjointLoader(dataset_train, node_level= True, batch_size=batch_size, epochs=200, shuffle=False, )\n",
    "loader_test = DisjointLoader(dataset_test, node_level = True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gcn_model():\n",
    "    # Define input placeholders for node features, adjacency matrix, and segment indices\n",
    "    X_in = Input(shape=(dataset.n_node_features,))\n",
    "    A_in = Input((None,), sparse=True)\n",
    "    I_in = Input(shape=(), dtype=tf.int32)\n",
    "\n",
    "    # Apply the first GINConv layer with 32 units and ReLU activation\n",
    "    X_1 = GINConv(32, activation=\"relu\")([X_in, A_in])\n",
    "    # Apply dropout with a rate of 0.5\n",
    "    X_1 = Dropout(0.5)(X_1)\n",
    "\n",
    "    # Apply the second GINConv layer with 32 units and ReLU activation\n",
    "    X_2 = GINConv(32, activation=\"relu\")([X_1, A_in])\n",
    "    # Apply dropout with a rate of 0.5\n",
    "    X_2 = Dropout(0.5)(X_2)\n",
    "\n",
    "    # Aggregate the node features using the segment_mean function and the segment indices\n",
    "    X_3 = tf.math.segment_mean(X_2, I_in)\n",
    "    # Apply a dense output layer with the number of labels and softmax activation\n",
    "    out = Dense(dataset.n_labels, activation=\"softmax\")(X_3)\n",
    "\n",
    "    # Create and return the model with the defined inputs and outputs\n",
    "    model = Model(inputs=[X_in, A_in, I_in], outputs=out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 02:32:49.860070: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-04 02:32:49.865269: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-04 02:32:49.868927: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-04 02:32:49.870086: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-04 02:32:49.870254: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-04 02:32:49.870408: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-04 02:32:50.406963: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-04 02:32:50.407162: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-04 02:32:50.407314: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-04 02:32:50.407430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10478 MB memory:  -> device: 0, name: NVIDIA TITAN V, pci bus id: 0000:08:00.0, compute capability: 7.0\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "#model = create_gcn_model()\n",
    "model = GCN(n_labels=dataset.n_labels)\n",
    "optimizer = Adam(lr=0.01)\n",
    "loss_fn = BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decorate the function with @tf.function to compile as a TensorFlow graph\n",
    "# Use the input_signature from loader_train and relax shapes for varying graph sizes\n",
    "#@tf.function(input_signature=loader_train.tf_signature(), experimental_relax_shapes=True)\n",
    "def train_step(inputs, target):\n",
    "    # Create a GradientTape context to record operations for automatic differentiation\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Compute model predictions with the inputs, set training=True for training-specific behaviors\n",
    "        predictions = model(inputs, training=True)\n",
    "        # Calculate the loss using the provided loss_fn and add the model's regularization losses\n",
    "        loss = loss_fn(target, predictions) + sum(model.losses)\n",
    "\n",
    "    # Compute gradients of the loss with respect to the model's trainable variables\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    # Apply the gradients to the model's variables using the optimizer's apply_gradients method\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    # Compute the accuracy using the categorical_accuracy function from TensorFlow\n",
    "    # Calculate the mean accuracy using tf.reduce_mean\n",
    "    acc = tf.reduce_mean(categorical_accuracy(target, predictions))\n",
    "\n",
    "    # Return the loss and accuracy as output\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(loader):\n",
    "    output = []\n",
    "    step = 0\n",
    "    while step < loader.steps_per_epoch:\n",
    "        step += 1\n",
    "        inputs, target = loader.__next__()\n",
    "        pred = model(inputs, training=False)\n",
    "        outs = (\n",
    "            loss_fn(target, pred),\n",
    "            tf.reduce_mean(categorical_accuracy(target, pred)),\n",
    "            len(target),  # Keep track of batch size\n",
    "        )\n",
    "        output.append(outs)\n",
    "        if step == loader.steps_per_epoch:\n",
    "            output = np.array(output)\n",
    "            return np.average(output[:, :-1], 0, weights=output[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 02:33:01.952204: W tensorflow/tsl/framework/bfc_allocator.cc:485] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.33TiB (rounded to 1465043952128)requested by op MatMul\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-05-04 02:33:01.952278: I tensorflow/tsl/framework/bfc_allocator.cc:1039] BFCAllocator dump for GPU_0_bfc\n",
      "2023-05-04 02:33:01.952301: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (256): \tTotal Chunks: 10, Chunks in use: 10. 2.5KiB allocated for chunks. 2.5KiB in use in bin. 56B client-requested in use in bin.\n",
      "2023-05-04 02:33:01.952320: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (512): \tTotal Chunks: 1, Chunks in use: 1. 512B allocated for chunks. 512B in use in bin. 448B client-requested in use in bin.\n",
      "2023-05-04 02:33:01.952339: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1024): \tTotal Chunks: 2, Chunks in use: 1. 2.5KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2023-05-04 02:33:01.952356: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-05-04 02:33:01.952372: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-05-04 02:33:01.952388: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-05-04 02:33:01.952403: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-05-04 02:33:01.952418: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-05-04 02:33:01.952434: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-05-04 02:33:01.952450: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-05-04 02:33:01.952466: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-05-04 02:33:01.952482: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-05-04 02:33:01.952497: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-05-04 02:33:01.952513: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-05-04 02:33:01.952533: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4194304): \tTotal Chunks: 4, Chunks in use: 2. 18.83MiB allocated for chunks. 9.33MiB in use in bin. 9.33MiB client-requested in use in bin.\n",
      "2023-05-04 02:33:01.952551: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8388608): \tTotal Chunks: 1, Chunks in use: 1. 9.23MiB allocated for chunks. 9.23MiB in use in bin. 9.23MiB client-requested in use in bin.\n",
      "2023-05-04 02:33:01.952570: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16777216): \tTotal Chunks: 4, Chunks in use: 3. 81.62MiB allocated for chunks. 58.53MiB in use in bin. 51.15MiB client-requested in use in bin.\n",
      "2023-05-04 02:33:01.952589: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (33554432): \tTotal Chunks: 7, Chunks in use: 5. 258.57MiB allocated for chunks. 184.69MiB in use in bin. 184.69MiB client-requested in use in bin.\n",
      "2023-05-04 02:33:01.952605: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-05-04 02:33:01.952620: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-05-04 02:33:01.952637: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (268435456): \tTotal Chunks: 1, Chunks in use: 0. 9.87GiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-05-04 02:33:01.952654: I tensorflow/tsl/framework/bfc_allocator.cc:1062] Bin for 1.33TiB was 256.00MiB, Chunk State: \n",
      "2023-05-04 02:33:01.952680: I tensorflow/tsl/framework/bfc_allocator.cc:1068]   Size: 9.87GiB | Requested Size: 0B | in_use: 0 | bin_num: 20, prev:   Size: 36.94MiB | Requested Size: 36.94MiB | in_use: 1 | bin_num: -1\n",
      "2023-05-04 02:33:01.952695: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 10987831296\n",
      "2023-05-04 02:33:01.952709: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7cd8000000 of size 256 next 1\n",
      "2023-05-04 02:33:01.952720: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7cd8000100 of size 1280 next 2\n",
      "2023-05-04 02:33:01.952732: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7cd8000600 of size 256 next 3\n",
      "2023-05-04 02:33:01.952743: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7cd8000700 of size 24684800 next 6\n",
      "2023-05-04 02:33:01.952755: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7cd978b000 of size 4936960 next 10\n",
      "2023-05-04 02:33:01.952766: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7cd9c40500 of size 256 next 7\n",
      "2023-05-04 02:33:01.952777: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7cd9c40600 of size 4841728 next 5\n",
      "2023-05-04 02:33:01.952789: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7cda0de700 of size 256 next 4\n",
      "2023-05-04 02:33:01.952799: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7cda0de800 of size 256 next 13\n",
      "2023-05-04 02:33:01.952810: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7cda0de900 of size 256 next 11\n",
      "2023-05-04 02:33:01.952821: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7cda0dea00 of size 256 next 17\n",
      "2023-05-04 02:33:01.952837: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7cda0deb00 of size 256 next 26\n",
      "2023-05-04 02:33:01.952848: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7cda0dec00 of size 256 next 27\n",
      "2023-05-04 02:33:01.952859: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f7cda0ded00 of size 1280 next 22\n",
      "2023-05-04 02:33:01.952869: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7cda0df200 of size 512 next 23\n",
      "2023-05-04 02:33:01.952880: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f7cda0df400 of size 4233728 next 14\n",
      "2023-05-04 02:33:01.952891: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7cda4e8e00 of size 256 next 15\n",
      "2023-05-04 02:33:01.952902: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f7cda4e8f00 of size 5731584 next 8\n",
      "2023-05-04 02:33:01.952913: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7cdaa60400 of size 19747584 next 9\n",
      "2023-05-04 02:33:01.952924: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7cdbd35700 of size 9683200 next 24\n",
      "2023-05-04 02:33:01.952935: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f7cdc671800 of size 24208128 next 12\n",
      "2023-05-04 02:33:01.952946: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7cddd87b00 of size 16945664 next 16\n",
      "2023-05-04 02:33:01.952957: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7cdedb0d00 of size 38732544 next 19\n",
      "2023-05-04 02:33:01.952968: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7ce12a1000 of size 38732544 next 20\n",
      "2023-05-04 02:33:01.952980: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7ce3791300 of size 38732544 next 18\n",
      "2023-05-04 02:33:01.952992: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f7ce5c81600 of size 38732544 next 21\n",
      "2023-05-04 02:33:01.953004: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7ce8171900 of size 38732544 next 25\n",
      "2023-05-04 02:33:01.953017: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f7cea661c00 of size 38732544 next 31\n",
      "2023-05-04 02:33:01.953028: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7cecb51f00 of size 38732544 next 30\n",
      "2023-05-04 02:33:01.953040: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f7cef042200 of size 10601684480 next 18446744073709551615\n",
      "2023-05-04 02:33:01.953052: I tensorflow/tsl/framework/bfc_allocator.cc:1100]      Summary of in-use Chunks by size: \n",
      "2023-05-04 02:33:01.953066: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 10 Chunks of size 256 totalling 2.5KiB\n",
      "2023-05-04 02:33:01.953079: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 512 totalling 512B\n",
      "2023-05-04 02:33:01.953092: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2023-05-04 02:33:01.953105: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 4841728 totalling 4.62MiB\n",
      "2023-05-04 02:33:01.953117: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 4936960 totalling 4.71MiB\n",
      "2023-05-04 02:33:01.953130: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 9683200 totalling 9.23MiB\n",
      "2023-05-04 02:33:01.953143: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 16945664 totalling 16.16MiB\n",
      "2023-05-04 02:33:01.953156: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 19747584 totalling 18.83MiB\n",
      "2023-05-04 02:33:01.953169: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 24684800 totalling 23.54MiB\n",
      "2023-05-04 02:33:01.953182: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 5 Chunks of size 38732544 totalling 184.69MiB\n",
      "2023-05-04 02:33:01.953195: I tensorflow/tsl/framework/bfc_allocator.cc:1107] Sum Total of in-use chunks: 261.79MiB\n",
      "2023-05-04 02:33:01.953207: I tensorflow/tsl/framework/bfc_allocator.cc:1109] Total bytes in pool: 10987831296 memory_limit_: 10987831296 available bytes: 0 curr_region_allocation_bytes_: 21975662592\n",
      "2023-05-04 02:33:01.953225: I tensorflow/tsl/framework/bfc_allocator.cc:1114] Stats: \n",
      "Limit:                     10987831296\n",
      "InUse:                       274507008\n",
      "MaxInUse:                    351972608\n",
      "NumAllocs:                          46\n",
      "MaxAllocSize:                 38732544\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2023-05-04 02:33:01.953239: W tensorflow/tsl/framework/bfc_allocator.cc:497] ****________________________________________________________________________________________________\n",
      "2023-05-04 02:33:01.953271: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at matmul_op_impl.h:730 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[605195,605195] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Exception encountered when calling layer 'gcn_conv_1' (type GCNConv).\n\n{{function_node __wrapped__MatMul_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[605195,605195] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:MatMul]\n\nCall arguments received by layer 'gcn_conv_1' (type GCNConv):\n  • inputs=['tf.Tensor(shape=(605195, 16), dtype=float32)', 'SparseTensor(indices=tf.Tensor(\\n[[     0 252661]\\n [     1  97219]\\n [     2  97219]\\n ...\\n [605191 605194]\\n [605192 605194]\\n [605193 605194]], shape=(1234211, 2), dtype=int64), values=tf.Tensor([2.239e+03 6.000e+00 2.000e+00 ... 6.000e+00 6.000e+00 1.200e+01], shape=(1234211,), dtype=float32), dense_shape=tf.Tensor([605195 605195], shape=(2,), dtype=int64))']\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m step \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[39m# Execute the train_step function with the current batch\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39m# Obtain the loss and accuracy\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m loss, acc \u001b[39m=\u001b[39m train_step(\u001b[39m*\u001b[39;49mbatch)\n\u001b[1;32m     16\u001b[0m \u001b[39m# Append the loss and accuracy to the results list\u001b[39;00m\n\u001b[1;32m     17\u001b[0m results\u001b[39m.\u001b[39mappend((loss, acc))\n",
      "Cell \u001b[0;32mIn[11], line 8\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(inputs, target)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_step\u001b[39m(inputs, target):\n\u001b[1;32m      5\u001b[0m     \u001b[39m# Create a GradientTape context to record operations for automatic differentiation\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mGradientTape() \u001b[39mas\u001b[39;00m tape:\n\u001b[1;32m      7\u001b[0m         \u001b[39m# Compute model predictions with the inputs, set training=True for training-specific behaviors\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m         predictions \u001b[39m=\u001b[39m model(inputs, training\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      9\u001b[0m         \u001b[39m# Calculate the loss using the provided loss_fn and add the model's regularization losses\u001b[39;00m\n\u001b[1;32m     10\u001b[0m         loss \u001b[39m=\u001b[39m loss_fn(target, predictions) \u001b[39m+\u001b[39m \u001b[39msum\u001b[39m(model\u001b[39m.\u001b[39mlosses)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/spektral/models/gcn.py:87\u001b[0m, in \u001b[0;36mGCN.call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     85\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gcn0([x, a])\n\u001b[1;32m     86\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_d1(x)\n\u001b[0;32m---> 87\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_gcn1([x, a])\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/spektral/layers/convolutional/conv.py:74\u001b[0m, in \u001b[0;36mcheck_dtypes_decorator.<locals>._inner_check_dtypes\u001b[0;34m(inputs, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[39m@wraps\u001b[39m(call)\n\u001b[1;32m     72\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_inner_check_dtypes\u001b[39m(inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     73\u001b[0m     inputs \u001b[39m=\u001b[39m check_dtypes(inputs)\n\u001b[0;32m---> 74\u001b[0m     \u001b[39mreturn\u001b[39;00m call(inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/spektral/layers/convolutional/gcn_conv.py:100\u001b[0m, in \u001b[0;36mGCNConv.call\u001b[0;34m(self, inputs, mask)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, inputs, mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     98\u001b[0m     x, a \u001b[39m=\u001b[39m inputs\n\u001b[0;32m--> 100\u001b[0m     output \u001b[39m=\u001b[39m K\u001b[39m.\u001b[39;49mdot(x, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel)\n\u001b[1;32m    101\u001b[0m     output \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mmodal_dot(a, output)\n\u001b[1;32m    103\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_bias:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Exception encountered when calling layer 'gcn_conv_1' (type GCNConv).\n\n{{function_node __wrapped__MatMul_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[605195,605195] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:MatMul]\n\nCall arguments received by layer 'gcn_conv_1' (type GCNConv):\n  • inputs=['tf.Tensor(shape=(605195, 16), dtype=float32)', 'SparseTensor(indices=tf.Tensor(\\n[[     0 252661]\\n [     1  97219]\\n [     2  97219]\\n ...\\n [605191 605194]\\n [605192 605194]\\n [605193 605194]], shape=(1234211, 2), dtype=int64), values=tf.Tensor([2.239e+03 6.000e+00 2.000e+00 ... 6.000e+00 6.000e+00 1.200e+01], shape=(1234211,), dtype=float32), dense_shape=tf.Tensor([605195 605195], shape=(2,), dtype=int64))']\n  • mask=None"
     ]
    }
   ],
   "source": [
    "# Initialize the epoch and step counters to -1\n",
    "# Create an empty list for storing training results\n",
    "epoch = step = -1\n",
    "results = []\n",
    "\n",
    "# Iterate through the batches in the loader_train data loader\n",
    "for batch in loader_train:\n",
    "    #print(batch)\n",
    "    # Increment the step counter\n",
    "    step += 1\n",
    "\n",
    "    # Execute the train_step function with the current batch\n",
    "    # Obtain the loss and accuracy\n",
    "    loss, acc = train_step(*batch)\n",
    "\n",
    "    # Append the loss and accuracy to the results list\n",
    "    results.append((loss, acc))\n",
    "\n",
    "    # Check if the current step is equal to the number of steps per epoch (loader_train.steps_per_epoch)\n",
    "    if step == loader_train.steps_per_epoch:\n",
    "        # Reset the step counter to 0\n",
    "        # Increment the epoch counter\n",
    "        step = 0\n",
    "        epoch += 1\n",
    "\n",
    "        # Evaluate the model on the test set using the evaluate function (which should be defined beforehand)\n",
    "        # Store the test results in results_te\n",
    "        results_te = evaluate(loader_test)\n",
    "\n",
    "        # Print the epoch number, mean training loss and accuracy, and test loss and accuracy\n",
    "        print(\n",
    "            \"Ep. {} - Loss: {:.3f} - Acc: {:.3f} - Test loss: {:.3f} - Test acc: {:.3f}\".format(\n",
    "                epoch, *np.mean(results, 0), *results_te\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Reset the results list to start collecting results for the next epoch\n",
    "        results = []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
