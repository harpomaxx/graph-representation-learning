{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: networkx in /usr/local/lib/python3.8/dist-packages (3.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Downloading seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
      "\u001b[K     |████████████████████████████████| 293 kB 928 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: matplotlib!=3.6.1,>=3.1 in /usr/local/lib/python3.8/dist-packages (from seaborn) (3.6.2)\n",
      "Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.8/dist-packages (from seaborn) (1.5.3)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in /usr/local/lib/python3.8/dist-packages (from seaborn) (1.23.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.0.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.38.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.25->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.14.0)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.12.2\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from spektral.data import Dataset, Graph\n",
    "from spektral.layers import GraphSageConv\n",
    "from spektral.utils import normalized_adjacency\n",
    "from spektral.models.gcn import GCN \n",
    "from spektral.datasets.utils import DATASET_FOLDER\n",
    "\n",
    "from scipy import sparse\n",
    "from scipy.special import softmax\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_graph_dir(G, communities=None):\n",
    "    pos = nx.spring_layout(G, seed=42)\n",
    "    \n",
    "    if communities is not None:\n",
    "        # Assign colors to nodes based on their communities\n",
    "        colors = ['orange' if community == 0 else 'skyblue' for community in communities]\n",
    "    else:\n",
    "        colors = 'red'\n",
    "\n",
    "    nx.draw_networkx(G, pos, arrows=True, node_color=colors, with_labels=True)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caso 1: dirigido, diferentes tamaños, NO balanceado (1%), clases separadas\n",
    "\n",
    "\n",
    "Tamaños: 25, 50, 100, 200, 400, 800, 1600, 3200, 6400, 12800\n",
    "\n",
    "Clases \"separadas\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class synthetic_Dir_diffSize_NoBalanced_1percent_clasesSep(Dataset):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    @property\n",
    "    def path(self):\n",
    "        return os.path.join(DATASET_FOLDER, \"syntheticGraphs\", self.__class__.__name__)\n",
    "    \n",
    "    def download(self):\n",
    "        os.makedirs(self.path)\n",
    "        \n",
    "        def generate_synthetic_graph_csbm(n_nodes, n_communities, n_features, edge_prob_matrix, node_feature_means,\\\n",
    "                                  n_infected, semilla, indice, feature_cov_matrix=None):\n",
    "            # Assign nodes to communities\n",
    "            np.random.seed(semilla*(indice+1))\n",
    "            indices = [np.random.randint(0,n_nodes) for i in range(n_infected)]\n",
    "            communities = np.array([int(j in indices) for j in range(n_nodes)])\n",
    "\n",
    "            # Generate node features\n",
    "            if feature_cov_matrix is None:\n",
    "                feature_cov_matrix = np.eye(n_features)\n",
    "            features = np.zeros((n_nodes, n_features))\n",
    "            for k in range(n_communities):\n",
    "                nodes_in_community = np.where(communities == k)[0]\n",
    "                features[nodes_in_community] = np.random.multivariate_normal(node_feature_means[k], feature_cov_matrix,\\\n",
    "                                                                             len(nodes_in_community))\n",
    "\n",
    "            # Compute community membership probabilities based on node features\n",
    "            community_membership_probs = softmax(features @ node_feature_means.T, axis=1)\n",
    "\n",
    "            # Generate edges based on community membership probabilities\n",
    "            adjacency_matrix = np.zeros((n_nodes, n_nodes))\n",
    "            for i in range(n_nodes):\n",
    "                for j in range(n_nodes):\n",
    "                    if i == j:\n",
    "                        continue\n",
    "                    community_i = communities[i]\n",
    "                    community_j = communities[j]\n",
    "                    edge_prob = edge_prob_matrix[community_i, community_j] * community_membership_probs[i, community_j] * community_membership_probs[j, community_i]\n",
    "                    adjacency_matrix[i, j] = np.random.binomial(1, edge_prob)\n",
    "\n",
    "            labels = tf.keras.utils.to_categorical(communities)\n",
    "            adjacency_matrix = sparse.csr_matrix(adjacency_matrix)\n",
    "            return Graph(x=features, a=adjacency_matrix, y=labels)\n",
    "\n",
    "        \n",
    "        n_graphs = 10\n",
    "        n_nodes = [25, 50, 100, 200, 400, 800, 1600, 3200, 6400, 12800]\n",
    "        n_features = 2\n",
    "        n_classes = 2\n",
    "        n_infected = [round((1/100)*n_nodes[i]) if (1/100)*n_nodes[i]>=1  else 1 for i in range(len(n_nodes))]\n",
    "        # Probability matrix for edges between communities\n",
    "        edge_prob_matrix = np.array([\n",
    "                                        [0.8, 0.2],\n",
    "                                        [0.3, 0.7]\n",
    "                                    ])\n",
    "        # Node feature means for each community\n",
    "        node_feature_means = np.array([\n",
    "                                        [2, 1], #, 0, 0, 0],\n",
    "                                        [1, 2] #, 0, 0, 0]\n",
    "                                    ])\n",
    "        \n",
    "        semillas = [123, 234, 345, 456, 567, 679, 789, 321, 654, 987]\n",
    "        \n",
    "        # Bien separadas las clases:\n",
    "        graphs1 = [generate_synthetic_graph_csbm(n_nodes[i], n_classes, n_features, edge_prob_matrix, node_feature_means, n_infected[i], semillas[i], 0, feature_cov_matrix=None) for i in range(n_graphs)]\n",
    "        for j in range(10):\n",
    "            filename = os.path.join(self.path, f'graph_Dir_NoBalanced_{n_infected[j]}a{n_nodes[j]}_clasesSep_0{j}.npz')\n",
    "            np.savez(filename, x=graphs1[j].x, a=graphs1[j].a, y=graphs1[j].y)\n",
    "\n",
    "        # Free memory\n",
    "        del graphs1\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "    def read(self):\n",
    "        # We must return a list of Graph objects\n",
    "        output = []\n",
    "\n",
    "        n_nodes = [25, 50, 100, 200, 400, 800, 1600, 3200, 6400, 12800]\n",
    "        n_infected = [round((1/100)*n_nodes[i]) if (1/100)*n_nodes[i]>=1  else 1 for i in range(len(n_nodes))]\n",
    "        \n",
    "        for j in range(10):\n",
    "            data1 = np.load(os.path.join(self.path, f'graph_Dir_NoBalanced_{n_infected[j]}a{n_nodes[j]}_clasesSep_0{j}.npz'), allow_pickle=True)\n",
    "            output.append(\n",
    "                Graph(x=data1['x'], a=data1['a'][()], y=data1['y']) # también puede ser a=data['a'].item()\n",
    "            )\n",
    "\n",
    "        return output\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = synthetic_Dir_diffSize_NoBalanced_1percent_clasesSep()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caso 2: dirigido, diferentes tamaños, NO balanceado (1%), clases mezcladas\n",
    "\n",
    "\n",
    "Tamaños: 25, 50, 100, 200, 400, 800, 1600, 3200, 6400, 12800\n",
    "\n",
    "Clases \"mezcladas\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class synthetic_Dir_diffSize_NoBalanced_1percent_clasesMezcl(Dataset):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    @property\n",
    "    def path(self):\n",
    "        return os.path.join(DATASET_FOLDER, \"syntheticGraphs\", self.__class__.__name__)\n",
    "    \n",
    "    def download(self):\n",
    "        os.makedirs(self.path)\n",
    "        \n",
    "        def generate_synthetic_graph_csbm(n_nodes, n_communities, n_features, edge_prob_matrix, node_feature_means,\\\n",
    "                                  n_infected, semilla, indice, feature_cov_matrix=None):\n",
    "            # Assign nodes to communities\n",
    "            np.random.seed(semilla*(indice+1))\n",
    "            indices = [np.random.randint(0,n_nodes) for i in range(n_infected)]\n",
    "            communities = np.array([int(j in indices) for j in range(n_nodes)])\n",
    "\n",
    "            # Generate node features\n",
    "            if feature_cov_matrix is None:\n",
    "                feature_cov_matrix = np.eye(n_features)\n",
    "            features = np.zeros((n_nodes, n_features))\n",
    "            for k in range(n_communities):\n",
    "                nodes_in_community = np.where(communities == k)[0]\n",
    "                features[nodes_in_community] = np.random.multivariate_normal(node_feature_means[k], feature_cov_matrix,\\\n",
    "                                                                             len(nodes_in_community))\n",
    "\n",
    "            # Compute community membership probabilities based on node features\n",
    "            community_membership_probs = softmax(features @ node_feature_means.T, axis=1)\n",
    "\n",
    "            # Generate edges based on community membership probabilities\n",
    "            adjacency_matrix = np.zeros((n_nodes, n_nodes))\n",
    "            for i in range(n_nodes):\n",
    "                for j in range(n_nodes):\n",
    "                    if i == j:\n",
    "                        continue\n",
    "                    community_i = communities[i]\n",
    "                    community_j = communities[j]\n",
    "                    edge_prob = edge_prob_matrix[community_i, community_j] * community_membership_probs[i, community_j] * community_membership_probs[j, community_i]\n",
    "                    adjacency_matrix[i, j] = np.random.binomial(1, edge_prob)\n",
    "\n",
    "            labels = tf.keras.utils.to_categorical(communities)\n",
    "            adjacency_matrix = sparse.csr_matrix(adjacency_matrix)\n",
    "            return Graph(x=features, a=adjacency_matrix, y=labels)\n",
    "\n",
    "        \n",
    "        n_graphs = 10\n",
    "        n_nodes = [25, 50, 100, 200, 400, 800, 1600, 3200, 6400, 12800]\n",
    "        n_features = 2\n",
    "        n_classes = 2\n",
    "        n_infected = [round((1/100)*n_nodes[i]) if (1/100)*n_nodes[i]>=1  else 1 for i in range(len(n_nodes))]\n",
    "        # Probability matrix for edges between communities\n",
    "        edge_prob_matrix = np.array([\n",
    "                                    [0.5, 0.5],\n",
    "                                    [0.5, 0.5]\n",
    "                            ])\n",
    "        # Node feature means for each community\n",
    "        node_feature_means = np.array([\n",
    "                                        [1, 1], #, 0, 0, 0],\n",
    "                                        [1, 1] #, 0, 0, 0]\n",
    "                                    ])\n",
    "        \n",
    "        semillas = [123, 234, 345, 456, 567, 678, 789, 321, 654, 987]\n",
    "        \n",
    "        # Clases un poco más juntas:\n",
    "        graphs2 = [generate_synthetic_graph_csbm(n_nodes[i], n_classes, n_features, edge_prob_matrix, node_feature_means, n_infected[i], semillas[i], 1, feature_cov_matrix=None) for i in range(n_graphs)]\n",
    "        for j in range(10):\n",
    "            filename = os.path.join(self.path, f'graph_Dir_NoBalanced_{n_infected[j]}a{n_nodes[j]}_clasesMezcl_2{j}.npz')\n",
    "            np.savez(filename, x=graphs2[j].x, a=graphs2[j].a, y=graphs2[j].y)\n",
    "\n",
    "        # Free memory\n",
    "        del graphs2\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "    def read(self):\n",
    "        # We must return a list of Graph objects\n",
    "        output = []\n",
    "        \n",
    "        n_nodes = [25, 50, 100, 200, 400, 800, 1600, 3200, 6400, 12800]\n",
    "        n_infected = [round((1/100)*n_nodes[i]) if (1/100)*n_nodes[i]>=1  else 1 for i in range(len(n_nodes))]\n",
    "        \n",
    "        for j in range(10):\n",
    "            data2 = np.load(os.path.join(self.path, f'graph_Dir_NoBalanced_{n_infected[j]}a{n_nodes[j]}_clasesMezcl_2{j}.npz'), allow_pickle=True)\n",
    "            output.append(\n",
    "                Graph(x=data2['x'], a=data2['a'][()], y=data2['y']) # también puede ser a=data['a'].item()\n",
    "            )\n",
    "\n",
    "        return output\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = synthetic_Dir_diffSize_NoBalanced_1percent_clasesMezcl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caso 3: dirigido, diferentes tamaños, NO balanceado (2%), clases separadas\n",
    "\n",
    "\n",
    "Tamaños: 25, 50, 100, 200, 400, 800, 1600, 3200, 6400, 12800\n",
    "\n",
    "Clases \"separadas\" (a juzgar por la representación gráfica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class synthetic_Dir_diffSize_NoBalanced_2percent_clasesSep(Dataset):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    @property\n",
    "    def path(self):\n",
    "        return os.path.join(DATASET_FOLDER, \"syntheticGraphs\", self.__class__.__name__)\n",
    "    \n",
    "    def download(self):\n",
    "        os.makedirs(self.path)\n",
    "        \n",
    "        def generate_synthetic_graph_csbm(n_nodes, n_communities, n_features, edge_prob_matrix, node_feature_means,\\\n",
    "                                  n_infected, semilla, indice, feature_cov_matrix=None):\n",
    "            # Assign nodes to communities\n",
    "            np.random.seed(semilla*(indice+1))\n",
    "            indices = [np.random.randint(0,n_nodes) for i in range(n_infected)]\n",
    "            communities = np.array([int(j in indices) for j in range(n_nodes)])\n",
    "\n",
    "            # Generate node features\n",
    "            if feature_cov_matrix is None:\n",
    "                feature_cov_matrix = np.eye(n_features)\n",
    "            features = np.zeros((n_nodes, n_features))\n",
    "            for k in range(n_communities):\n",
    "                nodes_in_community = np.where(communities == k)[0]\n",
    "                features[nodes_in_community] = np.random.multivariate_normal(node_feature_means[k], feature_cov_matrix,\\\n",
    "                                                                             len(nodes_in_community))\n",
    "\n",
    "            # Compute community membership probabilities based on node features\n",
    "            community_membership_probs = softmax(features @ node_feature_means.T, axis=1)\n",
    "\n",
    "            # Generate edges based on community membership probabilities\n",
    "            adjacency_matrix = np.zeros((n_nodes, n_nodes))\n",
    "            for i in range(n_nodes):\n",
    "                for j in range(n_nodes):\n",
    "                    if i == j:\n",
    "                        continue\n",
    "                    community_i = communities[i]\n",
    "                    community_j = communities[j]\n",
    "                    edge_prob = edge_prob_matrix[community_i, community_j] * community_membership_probs[i, community_j] * community_membership_probs[j, community_i]\n",
    "                    adjacency_matrix[i, j] = np.random.binomial(1, edge_prob)\n",
    "\n",
    "            labels = tf.keras.utils.to_categorical(communities)\n",
    "            adjacency_matrix = sparse.csr_matrix(adjacency_matrix)\n",
    "            return Graph(x=features, a=adjacency_matrix, y=labels)\n",
    "\n",
    "        \n",
    "        n_graphs = 10\n",
    "        n_nodes = [25, 50, 100, 200, 400, 800, 1600, 3200, 6400, 12800]\n",
    "        n_features = 2\n",
    "        n_classes = 2\n",
    "        n_infected = [round((2/100)*n_nodes[i]) if (2/100)*n_nodes[i]>=1  else 1 for i in range(len(n_nodes))]\n",
    "        # Probability matrix for edges between communities\n",
    "        edge_prob_matrix = np.array([\n",
    "                                        [0.8, 0.2],\n",
    "                                        [0.3, 0.7]\n",
    "                                    ])\n",
    "        # Node feature means for each community\n",
    "        node_feature_means = np.array([\n",
    "                                        [2, 1], #, 0, 0, 0],\n",
    "                                        [1, 2] #, 0, 0, 0]\n",
    "                                    ])\n",
    "        \n",
    "        semillas = [123, 234, 345, 456, 567, 679, 789, 321, 654, 987]\n",
    "        \n",
    "        # Bien separadas las clases:\n",
    "        graphs1 = [generate_synthetic_graph_csbm(n_nodes[i], n_classes, n_features, edge_prob_matrix, node_feature_means, n_infected[i], semillas[i], 0, feature_cov_matrix=None) for i in range(n_graphs)]\n",
    "        for j in range(10):\n",
    "            filename = os.path.join(self.path, f'graph_Dir_NoBalanced_{n_infected[j]}a{n_nodes[j]}_clasesSep_0{j}.npz')\n",
    "            np.savez(filename, x=graphs1[j].x, a=graphs1[j].a, y=graphs1[j].y)\n",
    "\n",
    "        # Free memory\n",
    "        del graphs1\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "    def read(self):\n",
    "        # We must return a list of Graph objects\n",
    "        output = []\n",
    "\n",
    "        n_nodes = [25, 50, 100, 200, 400, 800, 1600, 3200, 6400, 12800]\n",
    "        n_infected = [round((2/100)*n_nodes[i]) if (2/100)*n_nodes[i]>=1  else 1 for i in range(len(n_nodes))]\n",
    "        \n",
    "        for j in range(10):\n",
    "            data1 = np.load(os.path.join(self.path, f'graph_Dir_NoBalanced_{n_infected[j]}a{n_nodes[j]}_clasesSep_0{j}.npz'), allow_pickle=True)\n",
    "            output.append(\n",
    "                Graph(x=data1['x'], a=data1['a'][()], y=data1['y']) # también puede ser a=data['a'].item()\n",
    "            )\n",
    "\n",
    "        return output\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset3 = synthetic_Dir_diffSize_NoBalanced_2percent_clasesSep()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caso 4: dirigido, diferentes tamaños, NO balanceado (2%), clases \"mezcladas\"\n",
    "\n",
    "\n",
    "\n",
    "Tamaños: 25,50,100,200,400,800,1600,3200,6400,12800\n",
    "\n",
    "Clases \"mezcladas\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class synthetic_Dir_diffSize_NoBalanced_2percent_clasesMezcl(Dataset):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    @property\n",
    "    def path(self):\n",
    "        return os.path.join(DATASET_FOLDER, \"syntheticGraphs\", self.__class__.__name__)\n",
    "    \n",
    "    def download(self):\n",
    "        os.makedirs(self.path)\n",
    "        \n",
    "        def generate_synthetic_graph_csbm(n_nodes, n_communities, n_features, edge_prob_matrix, node_feature_means,\\\n",
    "                                  n_infected, semilla, indice, feature_cov_matrix=None):\n",
    "            # Assign nodes to communities\n",
    "            np.random.seed(semilla*(indice+1))\n",
    "            indices = [np.random.randint(0,n_nodes) for i in range(n_infected)]\n",
    "            communities = np.array([int(j in indices) for j in range(n_nodes)])\n",
    "\n",
    "            # Generate node features\n",
    "            if feature_cov_matrix is None:\n",
    "                feature_cov_matrix = np.eye(n_features)\n",
    "            features = np.zeros((n_nodes, n_features))\n",
    "            for k in range(n_communities):\n",
    "                nodes_in_community = np.where(communities == k)[0]\n",
    "                features[nodes_in_community] = np.random.multivariate_normal(node_feature_means[k], feature_cov_matrix,\\\n",
    "                                                                             len(nodes_in_community))\n",
    "\n",
    "            # Compute community membership probabilities based on node features\n",
    "            community_membership_probs = softmax(features @ node_feature_means.T, axis=1)\n",
    "\n",
    "            # Generate edges based on community membership probabilities\n",
    "            adjacency_matrix = np.zeros((n_nodes, n_nodes))\n",
    "            for i in range(n_nodes):\n",
    "                for j in range(n_nodes):\n",
    "                    if i == j:\n",
    "                        continue\n",
    "                    community_i = communities[i]\n",
    "                    community_j = communities[j]\n",
    "                    edge_prob = edge_prob_matrix[community_i, community_j] * community_membership_probs[i, community_j] * community_membership_probs[j, community_i]\n",
    "                    adjacency_matrix[i, j] = np.random.binomial(1, edge_prob)\n",
    "\n",
    "            labels = tf.keras.utils.to_categorical(communities)\n",
    "            adjacency_matrix = sparse.csr_matrix(adjacency_matrix)\n",
    "            return Graph(x=features, a=adjacency_matrix, y=labels)\n",
    "\n",
    "        \n",
    "        n_graphs = 10\n",
    "        n_nodes = [25, 50, 100, 200, 400, 800, 1600, 3200, 6400, 12800]\n",
    "        n_features = 2\n",
    "        n_classes = 2\n",
    "        n_infected = [round((2/100)*n_nodes[i]) if (2/100)*n_nodes[i]>=1  else 1 for i in range(len(n_nodes))]\n",
    "        # Probability matrix for edges between communities\n",
    "        edge_prob_matrix = np.array([\n",
    "                                    [0.5, 0.5],\n",
    "                                    [0.5, 0.5]\n",
    "                            ])\n",
    "        # Node feature means for each community\n",
    "        node_feature_means = np.array([\n",
    "                                        [1, 1], #, 0, 0, 0],\n",
    "                                        [1, 1] #, 0, 0, 0]\n",
    "                                    ])\n",
    "        \n",
    "        semillas = [123, 234, 345, 456, 567, 678, 789, 321, 654, 987]\n",
    "        \n",
    "        # Clases un poco más juntas:\n",
    "        graphs2 = [generate_synthetic_graph_csbm(n_nodes[i], n_classes, n_features, edge_prob_matrix, node_feature_means, n_infected[i], semillas[i], 1, feature_cov_matrix=None) for i in range(n_graphs)]\n",
    "        for j in range(10):\n",
    "            filename = os.path.join(self.path, f'graph_Dir_NoBalanced_{n_infected[j]}a{n_nodes[j]}_clasesMezcl_2{j}.npz')\n",
    "            np.savez(filename, x=graphs2[j].x, a=graphs2[j].a, y=graphs2[j].y)\n",
    "\n",
    "        # Free memory\n",
    "        del graphs2\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "    def read(self):\n",
    "        # We must return a list of Graph objects\n",
    "        output = []\n",
    "        \n",
    "        n_nodes = [25, 50, 100, 200, 400, 800, 1600, 3200, 6400, 12800]\n",
    "        n_infected = [round((2/100)*n_nodes[i]) if (2/100)*n_nodes[i]>=1  else 1 for i in range(len(n_nodes))]\n",
    "        \n",
    "        for j in range(10):\n",
    "            data2 = np.load(os.path.join(self.path, f'graph_Dir_NoBalanced_{n_infected[j]}a{n_nodes[j]}_clasesMezcl_2{j}.npz'), allow_pickle=True)\n",
    "            output.append(\n",
    "                Graph(x=data2['x'], a=data2['a'][()], y=data2['y']) # también puede ser a=data['a'].item()\n",
    "            )\n",
    "\n",
    "        return output\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset4 = synthetic_Dir_diffSize_NoBalanced_2percent_clasesMezcl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caso 5: dirigido, diferentes tamaños, NO balanceado (5%), clases separadas\n",
    "\n",
    "\n",
    "Tamaños: 25, 50, 100, 200, 400, 800, 1600, 3200, 6400, 12800\n",
    "\n",
    "Clases \"separadas\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class synthetic_Dir_diffSize_NoBalanced_5percent_clasesSep(Dataset):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    @property\n",
    "    def path(self):\n",
    "        return os.path.join(DATASET_FOLDER, \"syntheticGraphs\", self.__class__.__name__)\n",
    "    \n",
    "    def download(self):\n",
    "        os.makedirs(self.path)\n",
    "        \n",
    "        def generate_synthetic_graph_csbm(n_nodes, n_communities, n_features, edge_prob_matrix, node_feature_means,\\\n",
    "                                  n_infected, semilla, indice, feature_cov_matrix=None):\n",
    "            # Assign nodes to communities\n",
    "            np.random.seed(semilla*(indice+1))\n",
    "            indices = [np.random.randint(0,n_nodes) for i in range(n_infected)]\n",
    "            communities = np.array([int(j in indices) for j in range(n_nodes)])\n",
    "\n",
    "            # Generate node features\n",
    "            if feature_cov_matrix is None:\n",
    "                feature_cov_matrix = np.eye(n_features)\n",
    "            features = np.zeros((n_nodes, n_features))\n",
    "            for k in range(n_communities):\n",
    "                nodes_in_community = np.where(communities == k)[0]\n",
    "                features[nodes_in_community] = np.random.multivariate_normal(node_feature_means[k], feature_cov_matrix,\\\n",
    "                                                                             len(nodes_in_community))\n",
    "\n",
    "            # Compute community membership probabilities based on node features\n",
    "            community_membership_probs = softmax(features @ node_feature_means.T, axis=1)\n",
    "\n",
    "            # Generate edges based on community membership probabilities\n",
    "            adjacency_matrix = np.zeros((n_nodes, n_nodes))\n",
    "            for i in range(n_nodes):\n",
    "                for j in range(n_nodes):\n",
    "                    if i == j:\n",
    "                        continue\n",
    "                    community_i = communities[i]\n",
    "                    community_j = communities[j]\n",
    "                    edge_prob = edge_prob_matrix[community_i, community_j] * community_membership_probs[i, community_j] * community_membership_probs[j, community_i]\n",
    "                    adjacency_matrix[i, j] = np.random.binomial(1, edge_prob)\n",
    "\n",
    "            labels = tf.keras.utils.to_categorical(communities)\n",
    "            adjacency_matrix = sparse.csr_matrix(adjacency_matrix)\n",
    "            return Graph(x=features, a=adjacency_matrix, y=labels)\n",
    "\n",
    "        \n",
    "        n_graphs = 10\n",
    "        n_nodes = [25, 50, 100, 200, 400, 800, 1600, 3200, 6400, 12800]\n",
    "        n_features = 2\n",
    "        n_classes = 2\n",
    "        n_infected = [round((5/100)*n_nodes[i]) if (5/100)*n_nodes[i]>=1  else 1 for i in range(len(n_nodes))]\n",
    "        # Probability matrix for edges between communities\n",
    "        edge_prob_matrix = np.array([\n",
    "                                        [0.8, 0.2],\n",
    "                                        [0.3, 0.7]\n",
    "                                    ])\n",
    "        # Node feature means for each community\n",
    "        node_feature_means = np.array([\n",
    "                                        [2, 1], #, 0, 0, 0],\n",
    "                                        [1, 2] #, 0, 0, 0]\n",
    "                                    ])\n",
    "        \n",
    "        semillas = [123, 234, 345, 456, 567, 679, 789, 321, 654, 987]\n",
    "        \n",
    "        # Bien separadas las clases:\n",
    "        graphs1 = [generate_synthetic_graph_csbm(n_nodes[i], n_classes, n_features, edge_prob_matrix, node_feature_means, n_infected[i], semillas[i], 0, feature_cov_matrix=None) for i in range(n_graphs)]\n",
    "        for j in range(10):\n",
    "            filename = os.path.join(self.path, f'graph_Dir_NoBalanced_{n_infected[j]}a{n_nodes[j]}_clasesSep_0{j}.npz')\n",
    "            np.savez(filename, x=graphs1[j].x, a=graphs1[j].a, y=graphs1[j].y)\n",
    "\n",
    "        # Free memory\n",
    "        del graphs1\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "    def read(self):\n",
    "        # We must return a list of Graph objects\n",
    "        output = []\n",
    "\n",
    "        n_nodes = [25, 50, 100, 200, 400, 800, 1600, 3200, 6400, 12800]\n",
    "        n_infected = [round((5/100)*n_nodes[i]) if (5/100)*n_nodes[i]>=1  else 1 for i in range(len(n_nodes))]\n",
    "        \n",
    "        for j in range(10):\n",
    "            data1 = np.load(os.path.join(self.path, f'graph_Dir_NoBalanced_{n_infected[j]}a{n_nodes[j]}_clasesSep_0{j}.npz'), allow_pickle=True)\n",
    "            output.append(\n",
    "                Graph(x=data1['x'], a=data1['a'][()], y=data1['y']) # también puede ser a=data['a'].item()\n",
    "            )\n",
    "\n",
    "        return output\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset5 = synthetic_Dir_diffSize_NoBalanced_5percent_clasesSep()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caso 6: dirigido, diferentes tamaños, NO balanceado (5%), clases mezcladas\n",
    "\n",
    "\n",
    "Tamaños: 25, 50, 100, 200, 400, 800, 1600, 3200, 6400, 12800\n",
    "\n",
    "Clases \"mezcladas\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class synthetic_Dir_diffSize_NoBalanced_5percent_clasesMezcl(Dataset):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    @property\n",
    "    def path(self):\n",
    "        return os.path.join(DATASET_FOLDER, \"syntheticGraphs\", self.__class__.__name__)\n",
    "    \n",
    "    def download(self):\n",
    "        os.makedirs(self.path)\n",
    "        \n",
    "        def generate_synthetic_graph_csbm(n_nodes, n_communities, n_features, edge_prob_matrix, node_feature_means,\\\n",
    "                                  n_infected, semilla, indice, feature_cov_matrix=None):\n",
    "            # Assign nodes to communities\n",
    "            np.random.seed(semilla*(indice+1))\n",
    "            indices = [np.random.randint(0,n_nodes) for i in range(n_infected)]\n",
    "            communities = np.array([int(j in indices) for j in range(n_nodes)])\n",
    "\n",
    "            # Generate node features\n",
    "            if feature_cov_matrix is None:\n",
    "                feature_cov_matrix = np.eye(n_features)\n",
    "            features = np.zeros((n_nodes, n_features))\n",
    "            for k in range(n_communities):\n",
    "                nodes_in_community = np.where(communities == k)[0]\n",
    "                features[nodes_in_community] = np.random.multivariate_normal(node_feature_means[k], feature_cov_matrix,\\\n",
    "                                                                             len(nodes_in_community))\n",
    "\n",
    "            # Compute community membership probabilities based on node features\n",
    "            community_membership_probs = softmax(features @ node_feature_means.T, axis=1)\n",
    "\n",
    "            # Generate edges based on community membership probabilities\n",
    "            adjacency_matrix = np.zeros((n_nodes, n_nodes))\n",
    "            for i in range(n_nodes):\n",
    "                for j in range(n_nodes):\n",
    "                    if i == j:\n",
    "                        continue\n",
    "                    community_i = communities[i]\n",
    "                    community_j = communities[j]\n",
    "                    edge_prob = edge_prob_matrix[community_i, community_j] * community_membership_probs[i, community_j] * community_membership_probs[j, community_i]\n",
    "                    adjacency_matrix[i, j] = np.random.binomial(1, edge_prob)\n",
    "\n",
    "            labels = tf.keras.utils.to_categorical(communities)\n",
    "            adjacency_matrix = sparse.csr_matrix(adjacency_matrix)\n",
    "            return Graph(x=features, a=adjacency_matrix, y=labels)\n",
    "\n",
    "        \n",
    "        n_graphs = 10\n",
    "        n_nodes = [25, 50, 100, 200, 400, 800, 1600, 3200, 6400, 12800]\n",
    "        n_features = 2\n",
    "        n_classes = 2\n",
    "        n_infected = [round((5/100)*n_nodes[i]) if (5/100)*n_nodes[i]>=1  else 1 for i in range(len(n_nodes))]\n",
    "        # Probability matrix for edges between communities\n",
    "        edge_prob_matrix = np.array([\n",
    "                                    [0.5, 0.5],\n",
    "                                    [0.5, 0.5]\n",
    "                            ])\n",
    "        # Node feature means for each community\n",
    "        node_feature_means = np.array([\n",
    "                                        [1, 1], #, 0, 0, 0],\n",
    "                                        [1, 1] #, 0, 0, 0]\n",
    "                                    ])\n",
    "        \n",
    "        semillas = [123, 234, 345, 456, 567, 678, 789, 321, 654, 987]\n",
    "        \n",
    "        # Clases un poco más juntas:\n",
    "        graphs2 = [generate_synthetic_graph_csbm(n_nodes[i], n_classes, n_features, edge_prob_matrix, node_feature_means, n_infected[i], semillas[i], 1, feature_cov_matrix=None) for i in range(n_graphs)]\n",
    "        for j in range(10):\n",
    "            filename = os.path.join(self.path, f'graph_Dir_NoBalanced_{n_infected[j]}a{n_nodes[j]}_clasesMezcl_2{j}.npz')\n",
    "            np.savez(filename, x=graphs2[j].x, a=graphs2[j].a, y=graphs2[j].y)\n",
    "\n",
    "        # Free memory\n",
    "        del graphs2\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "    def read(self):\n",
    "        # We must return a list of Graph objects\n",
    "        output = []\n",
    "        \n",
    "        n_nodes = [25, 50, 100, 200, 400, 800, 1600, 3200, 6400, 12800]\n",
    "        n_infected = [round((5/100)*n_nodes[i]) if (5/100)*n_nodes[i]>=1  else 1 for i in range(len(n_nodes))]\n",
    "        \n",
    "        for j in range(10):\n",
    "            data2 = np.load(os.path.join(self.path, f'graph_Dir_NoBalanced_{n_infected[j]}a{n_nodes[j]}_clasesMezcl_2{j}.npz'), allow_pickle=True)\n",
    "            output.append(\n",
    "                Graph(x=data2['x'], a=data2['a'][()], y=data2['y']) # también puede ser a=data['a'].item()\n",
    "            )\n",
    "\n",
    "        return output\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset6 = synthetic_Dir_diffSize_NoBalanced_5percent_clasesMezcl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caso 7: dirigido, diferentes tamaños, NO balanceado (10%), clases separadas\n",
    "\n",
    "\n",
    "Tamaños: 25, 50, 100, 200, 400, 800, 1600, 3200, 6400, 12800\n",
    "\n",
    "Clases \"separadas\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class synthetic_Dir_diffSize_NoBalanced_10percent_clasesSep(Dataset):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    @property\n",
    "    def path(self):\n",
    "        return os.path.join(DATASET_FOLDER, \"syntheticGraphs\", self.__class__.__name__)\n",
    "    \n",
    "    def download(self):\n",
    "        os.makedirs(self.path)\n",
    "        \n",
    "        def generate_synthetic_graph_csbm(n_nodes, n_communities, n_features, edge_prob_matrix, node_feature_means,\\\n",
    "                                  n_infected, semilla, indice, feature_cov_matrix=None):\n",
    "            # Assign nodes to communities\n",
    "            np.random.seed(semilla*(indice+1))\n",
    "            indices = [np.random.randint(0,n_nodes) for i in range(n_infected)]\n",
    "            communities = np.array([int(j in indices) for j in range(n_nodes)])\n",
    "\n",
    "            # Generate node features\n",
    "            if feature_cov_matrix is None:\n",
    "                feature_cov_matrix = np.eye(n_features)\n",
    "            features = np.zeros((n_nodes, n_features))\n",
    "            for k in range(n_communities):\n",
    "                nodes_in_community = np.where(communities == k)[0]\n",
    "                features[nodes_in_community] = np.random.multivariate_normal(node_feature_means[k], feature_cov_matrix,\\\n",
    "                                                                             len(nodes_in_community))\n",
    "\n",
    "            # Compute community membership probabilities based on node features\n",
    "            community_membership_probs = softmax(features @ node_feature_means.T, axis=1)\n",
    "\n",
    "            # Generate edges based on community membership probabilities\n",
    "            adjacency_matrix = np.zeros((n_nodes, n_nodes))\n",
    "            for i in range(n_nodes):\n",
    "                for j in range(n_nodes):\n",
    "                    if i == j:\n",
    "                        continue\n",
    "                    community_i = communities[i]\n",
    "                    community_j = communities[j]\n",
    "                    edge_prob = edge_prob_matrix[community_i, community_j] * community_membership_probs[i, community_j] * community_membership_probs[j, community_i]\n",
    "                    adjacency_matrix[i, j] = np.random.binomial(1, edge_prob)\n",
    "\n",
    "            labels = tf.keras.utils.to_categorical(communities)\n",
    "            adjacency_matrix = sparse.csr_matrix(adjacency_matrix)\n",
    "            return Graph(x=features, a=adjacency_matrix, y=labels)\n",
    "\n",
    "        \n",
    "        n_graphs = 10\n",
    "        n_nodes = [25, 50, 100, 200, 400, 800, 1600, 3200, 6400, 12800]\n",
    "        n_features = 2\n",
    "        n_classes = 2\n",
    "        n_infected = [round((10/100)*n_nodes[i]) if (10/100)*n_nodes[i]>=1  else 1 for i in range(len(n_nodes))]\n",
    "        # Probability matrix for edges between communities\n",
    "        edge_prob_matrix = np.array([\n",
    "                                        [0.8, 0.2],\n",
    "                                        [0.3, 0.7]\n",
    "                                    ])\n",
    "        # Node feature means for each community\n",
    "        node_feature_means = np.array([\n",
    "                                        [2, 1], #, 0, 0, 0],\n",
    "                                        [1, 2] #, 0, 0, 0]\n",
    "                                    ])\n",
    "        \n",
    "        semillas = [123, 234, 345, 456, 567, 679, 789, 321, 654, 987]\n",
    "        \n",
    "        # Bien separadas las clases:\n",
    "        graphs1 = [generate_synthetic_graph_csbm(n_nodes[i], n_classes, n_features, edge_prob_matrix, node_feature_means, n_infected[i], semillas[i], 0, feature_cov_matrix=None) for i in range(n_graphs)]\n",
    "        for j in range(10):\n",
    "            filename = os.path.join(self.path, f'graph_Dir_NoBalanced_{n_infected[j]}a{n_nodes[j]}_clasesSep_0{j}.npz')\n",
    "            np.savez(filename, x=graphs1[j].x, a=graphs1[j].a, y=graphs1[j].y)\n",
    "\n",
    "        # Free memory\n",
    "        del graphs1\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "    def read(self):\n",
    "        # We must return a list of Graph objects\n",
    "        output = []\n",
    "\n",
    "        n_nodes = [25, 50, 100, 200, 400, 800, 1600, 3200, 6400, 12800]\n",
    "        n_infected = [round((10/100)*n_nodes[i]) if (10/100)*n_nodes[i]>=1  else 1 for i in range(len(n_nodes))]\n",
    "        \n",
    "        for j in range(10):\n",
    "            data1 = np.load(os.path.join(self.path, f'graph_Dir_NoBalanced_{n_infected[j]}a{n_nodes[j]}_clasesSep_0{j}.npz'), allow_pickle=True)\n",
    "            output.append(\n",
    "                Graph(x=data1['x'], a=data1['a'][()], y=data1['y']) # también puede ser a=data['a'].item()\n",
    "            )\n",
    "\n",
    "        return output\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset7 = synthetic_Dir_diffSize_NoBalanced_10percent_clasesSep()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caso 8: dirigido, diferentes tamaños, NO balanceado (10%), clases mezcladas\n",
    "\n",
    "\n",
    "Tamaños: 25, 50, 100, 200, 400, 800, 1600, 3200, 6400, 12800\n",
    "\n",
    "Clases \"mezcladas\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class synthetic_Dir_diffSize_NoBalanced_10percent_clasesMezcl(Dataset):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    @property\n",
    "    def path(self):\n",
    "        return os.path.join(DATASET_FOLDER, \"syntheticGraphs\", self.__class__.__name__)\n",
    "    \n",
    "    def download(self):\n",
    "        os.makedirs(self.path)\n",
    "        \n",
    "        def generate_synthetic_graph_csbm(n_nodes, n_communities, n_features, edge_prob_matrix, node_feature_means,\\\n",
    "                                  n_infected, semilla, indice, feature_cov_matrix=None):\n",
    "            # Assign nodes to communities\n",
    "            np.random.seed(semilla*(indice+1))\n",
    "            indices = [np.random.randint(0,n_nodes) for i in range(n_infected)]\n",
    "            communities = np.array([int(j in indices) for j in range(n_nodes)])\n",
    "\n",
    "            # Generate node features\n",
    "            if feature_cov_matrix is None:\n",
    "                feature_cov_matrix = np.eye(n_features)\n",
    "            features = np.zeros((n_nodes, n_features))\n",
    "            for k in range(n_communities):\n",
    "                nodes_in_community = np.where(communities == k)[0]\n",
    "                features[nodes_in_community] = np.random.multivariate_normal(node_feature_means[k], feature_cov_matrix,\\\n",
    "                                                                             len(nodes_in_community))\n",
    "\n",
    "            # Compute community membership probabilities based on node features\n",
    "            community_membership_probs = softmax(features @ node_feature_means.T, axis=1)\n",
    "\n",
    "            # Generate edges based on community membership probabilities\n",
    "            adjacency_matrix = np.zeros((n_nodes, n_nodes))\n",
    "            for i in range(n_nodes):\n",
    "                for j in range(n_nodes):\n",
    "                    if i == j:\n",
    "                        continue\n",
    "                    community_i = communities[i]\n",
    "                    community_j = communities[j]\n",
    "                    edge_prob = edge_prob_matrix[community_i, community_j] * community_membership_probs[i, community_j] * community_membership_probs[j, community_i]\n",
    "                    adjacency_matrix[i, j] = np.random.binomial(1, edge_prob)\n",
    "\n",
    "            labels = tf.keras.utils.to_categorical(communities)\n",
    "            adjacency_matrix = sparse.csr_matrix(adjacency_matrix)\n",
    "            return Graph(x=features, a=adjacency_matrix, y=labels)\n",
    "\n",
    "        \n",
    "        n_graphs = 10\n",
    "        n_nodes = [25, 50, 100, 200, 400, 800, 1600, 3200, 6400, 12800]\n",
    "        n_features = 2\n",
    "        n_classes = 2\n",
    "        n_infected = [round((10/100)*n_nodes[i]) if (10/100)*n_nodes[i]>=1  else 1 for i in range(len(n_nodes))]\n",
    "        # Probability matrix for edges between communities\n",
    "        edge_prob_matrix = np.array([\n",
    "                                    [0.5, 0.5],\n",
    "                                    [0.5, 0.5]\n",
    "                            ])\n",
    "        # Node feature means for each community\n",
    "        node_feature_means = np.array([\n",
    "                                        [1, 1], #, 0, 0, 0],\n",
    "                                        [1, 1] #, 0, 0, 0]\n",
    "                                    ])\n",
    "        \n",
    "        semillas = [123, 234, 345, 456, 567, 678, 789, 321, 654, 987]\n",
    "        \n",
    "        # Clases un poco más juntas:\n",
    "        graphs2 = [generate_synthetic_graph_csbm(n_nodes[i], n_classes, n_features, edge_prob_matrix, node_feature_means, n_infected[i], semillas[i], 1, feature_cov_matrix=None) for i in range(n_graphs)]\n",
    "        for j in range(10):\n",
    "            filename = os.path.join(self.path, f'graph_Dir_NoBalanced_{n_infected[j]}a{n_nodes[j]}_clasesMezcl_2{j}.npz')\n",
    "            np.savez(filename, x=graphs2[j].x, a=graphs2[j].a, y=graphs2[j].y)\n",
    "\n",
    "        # Free memory\n",
    "        del graphs2\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "    def read(self):\n",
    "        # We must return a list of Graph objects\n",
    "        output = []\n",
    "        \n",
    "        n_nodes = [25, 50, 100, 200, 400, 800, 1600, 3200, 6400, 12800]\n",
    "        n_infected = [round((10/100)*n_nodes[i]) if (10/100)*n_nodes[i]>=1  else 1 for i in range(len(n_nodes))]\n",
    "        \n",
    "        for j in range(10):\n",
    "            data2 = np.load(os.path.join(self.path, f'graph_Dir_NoBalanced_{n_infected[j]}a{n_nodes[j]}_clasesMezcl_2{j}.npz'), allow_pickle=True)\n",
    "            output.append(\n",
    "                Graph(x=data2['x'], a=data2['a'][()], y=data2['y']) # también puede ser a=data['a'].item()\n",
    "            )\n",
    "\n",
    "        return output\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset8 = synthetic_Dir_diffSize_NoBalanced_10percent_clasesMezcl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caso 9: dirigido, diferentes tamaños, NO balanceado (20%), clases separadas\n",
    "\n",
    "\n",
    "Tamaños: 25,50,100,200,400,800,1600,3200,6400,12800\n",
    "\n",
    "Clases \"separadas\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class synthetic_Dir_diffSize_NoBalanced_20percent_clasesSep(Dataset):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    @property\n",
    "    def path(self):\n",
    "        return os.path.join(DATASET_FOLDER, \"syntheticGraphs\", self.__class__.__name__)\n",
    "    \n",
    "    def download(self):\n",
    "        os.makedirs(self.path)\n",
    "        \n",
    "        def generate_synthetic_graph_csbm(n_nodes, n_communities, n_features, edge_prob_matrix, node_feature_means,\\\n",
    "                                  n_infected, semilla, indice, feature_cov_matrix=None):\n",
    "            # Assign nodes to communities\n",
    "            np.random.seed(semilla*(indice+1))\n",
    "            indices = [np.random.randint(0,n_nodes) for i in range(n_infected)]\n",
    "            communities = np.array([int(j in indices) for j in range(n_nodes)])\n",
    "\n",
    "            # Generate node features\n",
    "            if feature_cov_matrix is None:\n",
    "                feature_cov_matrix = np.eye(n_features)\n",
    "            features = np.zeros((n_nodes, n_features))\n",
    "            for k in range(n_communities):\n",
    "                nodes_in_community = np.where(communities == k)[0]\n",
    "                features[nodes_in_community] = np.random.multivariate_normal(node_feature_means[k], feature_cov_matrix,\\\n",
    "                                                                             len(nodes_in_community))\n",
    "\n",
    "            # Compute community membership probabilities based on node features\n",
    "            community_membership_probs = softmax(features @ node_feature_means.T, axis=1)\n",
    "\n",
    "            # Generate edges based on community membership probabilities\n",
    "            adjacency_matrix = np.zeros((n_nodes, n_nodes))\n",
    "            for i in range(n_nodes):\n",
    "                for j in range(n_nodes):\n",
    "                    if i == j:\n",
    "                        continue\n",
    "                    community_i = communities[i]\n",
    "                    community_j = communities[j]\n",
    "                    edge_prob = edge_prob_matrix[community_i, community_j] * community_membership_probs[i, community_j] * community_membership_probs[j, community_i]\n",
    "                    adjacency_matrix[i, j] = np.random.binomial(1, edge_prob)\n",
    "\n",
    "            labels = tf.keras.utils.to_categorical(communities)\n",
    "            adjacency_matrix = sparse.csr_matrix(adjacency_matrix)\n",
    "            return Graph(x=features, a=adjacency_matrix, y=labels)\n",
    "\n",
    "        \n",
    "        n_graphs = 10\n",
    "        n_nodes = [25, 50, 100, 200, 400, 800, 1600, 3200, 6400, 12800]\n",
    "        n_features = 2\n",
    "        n_classes = 2\n",
    "        n_infected = [round((20/100)*n_nodes[i]) if (20/100)*n_nodes[i]>=1  else 1 for i in range(len(n_nodes))]\n",
    "        # Probability matrix for edges between communities\n",
    "        edge_prob_matrix = np.array([\n",
    "                                        [0.8, 0.2],\n",
    "                                        [0.3, 0.7]\n",
    "                                    ])\n",
    "        # Node feature means for each community\n",
    "        node_feature_means = np.array([\n",
    "                                        [2, 1], #, 0, 0, 0],\n",
    "                                        [1, 2] #, 0, 0, 0]\n",
    "                                    ])\n",
    "        \n",
    "        semillas = [123, 234, 345, 456, 567, 679, 789, 321, 654, 987]\n",
    "        \n",
    "        # Bien separadas las clases:\n",
    "        graphs1 = [generate_synthetic_graph_csbm(n_nodes[i], n_classes, n_features, edge_prob_matrix, node_feature_means, n_infected[i], semillas[i], 0, feature_cov_matrix=None) for i in range(n_graphs)]\n",
    "        for j in range(10):\n",
    "            filename = os.path.join(self.path, f'graph_Dir_NoBalanced_{n_infected[j]}a{n_nodes[j]}_clasesSep_0{j}.npz')\n",
    "            np.savez(filename, x=graphs1[j].x, a=graphs1[j].a, y=graphs1[j].y)\n",
    "\n",
    "        # Free memory\n",
    "        del graphs1\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "    def read(self):\n",
    "        # We must return a list of Graph objects\n",
    "        output = []\n",
    "\n",
    "        n_nodes = [25, 50, 100, 200, 400, 800, 1600, 3200, 6400, 12800]\n",
    "        n_infected = [round((20/100)*n_nodes[i]) if (20/100)*n_nodes[i]>=1  else 1 for i in range(len(n_nodes))]\n",
    "        \n",
    "        for j in range(10):\n",
    "            data1 = np.load(os.path.join(self.path, f'graph_Dir_NoBalanced_{n_infected[j]}a{n_nodes[j]}_clasesSep_0{j}.npz'), allow_pickle=True)\n",
    "            output.append(\n",
    "                Graph(x=data1['x'], a=data1['a'][()], y=data1['y']) # también puede ser a=data['a'].item()\n",
    "            )\n",
    "\n",
    "        return output\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset9 = synthetic_Dir_diffSize_NoBalanced_20percent_clasesSep()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caso 10: dirigido, diferentes tamaños, NO balanceado (20%), clases mezcladas\n",
    "\n",
    "\n",
    "Tamaños: 25,50,100,200,400,800,1600,3200,6400,12800\n",
    "\n",
    "Clases \"mezcladas\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class synthetic_Dir_diffSize_NoBalanced_20percent_clasesMezcl(Dataset):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    @property\n",
    "    def path(self):\n",
    "        return os.path.join(DATASET_FOLDER, \"syntheticGraphs\", self.__class__.__name__)\n",
    "    \n",
    "    def download(self):\n",
    "        os.makedirs(self.path)\n",
    "        \n",
    "        def generate_synthetic_graph_csbm(n_nodes, n_communities, n_features, edge_prob_matrix, node_feature_means,\\\n",
    "                                  n_infected, semilla, indice, feature_cov_matrix=None):\n",
    "            # Assign nodes to communities\n",
    "            np.random.seed(semilla*(indice+1))\n",
    "            indices = [np.random.randint(0,n_nodes) for i in range(n_infected)]\n",
    "            communities = np.array([int(j in indices) for j in range(n_nodes)])\n",
    "\n",
    "            # Generate node features\n",
    "            if feature_cov_matrix is None:\n",
    "                feature_cov_matrix = np.eye(n_features)\n",
    "            features = np.zeros((n_nodes, n_features))\n",
    "            for k in range(n_communities):\n",
    "                nodes_in_community = np.where(communities == k)[0]\n",
    "                features[nodes_in_community] = np.random.multivariate_normal(node_feature_means[k], feature_cov_matrix,\\\n",
    "                                                                             len(nodes_in_community))\n",
    "\n",
    "            # Compute community membership probabilities based on node features\n",
    "            community_membership_probs = softmax(features @ node_feature_means.T, axis=1)\n",
    "\n",
    "            # Generate edges based on community membership probabilities\n",
    "            adjacency_matrix = np.zeros((n_nodes, n_nodes))\n",
    "            for i in range(n_nodes):\n",
    "                for j in range(n_nodes):\n",
    "                    if i == j:\n",
    "                        continue\n",
    "                    community_i = communities[i]\n",
    "                    community_j = communities[j]\n",
    "                    edge_prob = edge_prob_matrix[community_i, community_j] * community_membership_probs[i, community_j] * community_membership_probs[j, community_i]\n",
    "                    adjacency_matrix[i, j] = np.random.binomial(1, edge_prob)\n",
    "\n",
    "            labels = tf.keras.utils.to_categorical(communities)\n",
    "            adjacency_matrix = sparse.csr_matrix(adjacency_matrix)\n",
    "            return Graph(x=features, a=adjacency_matrix, y=labels)\n",
    "\n",
    "        \n",
    "        n_graphs = 10\n",
    "        n_nodes = [25, 50, 100, 200, 400, 800, 1600, 3200, 6400, 12800]\n",
    "        n_features = 2\n",
    "        n_classes = 2\n",
    "        n_infected = [round((20/100)*n_nodes[i]) if (20/100)*n_nodes[i]>=1  else 1 for i in range(len(n_nodes))]\n",
    "        # Probability matrix for edges between communities\n",
    "        edge_prob_matrix = np.array([\n",
    "                                    [0.5, 0.5],\n",
    "                                    [0.5, 0.5]\n",
    "                            ])\n",
    "        # Node feature means for each community\n",
    "        node_feature_means = np.array([\n",
    "                                        [1, 1], #, 0, 0, 0],\n",
    "                                        [1, 1] #, 0, 0, 0]\n",
    "                                    ])\n",
    "        \n",
    "        semillas = [123, 234, 345, 456, 567, 678, 789, 321, 654, 987]\n",
    "        \n",
    "        # Clases un poco más juntas:\n",
    "        graphs2 = [generate_synthetic_graph_csbm(n_nodes[i], n_classes, n_features, edge_prob_matrix, node_feature_means, n_infected[i], semillas[i], 1, feature_cov_matrix=None) for i in range(n_graphs)]\n",
    "        for j in range(10):\n",
    "            filename = os.path.join(self.path, f'graph_Dir_NoBalanced_{n_infected[j]}a{n_nodes[j]}_clasesMezcl_2{j}.npz')\n",
    "            np.savez(filename, x=graphs2[j].x, a=graphs2[j].a, y=graphs2[j].y)\n",
    "\n",
    "        # Free memory\n",
    "        del graphs2\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "    def read(self):\n",
    "        # We must return a list of Graph objects\n",
    "        output = []\n",
    "\n",
    "        n_nodes = [25, 50, 100, 200, 400, 800, 1600, 3200, 6400, 12800]\n",
    "        n_infected = [round((20/100)*n_nodes[i]) if (20/100)*n_nodes[i]>=1  else 1 for i in range(len(n_nodes))]\n",
    "        \n",
    "        for j in range(10):\n",
    "            data2 = np.load(os.path.join(self.path, f'graph_Dir_NoBalanced_{n_infected[j]}a{n_nodes[j]}_clasesMezcl_2{j}.npz'), allow_pickle=True)\n",
    "            output.append(\n",
    "                Graph(x=data2['x'], a=data2['a'][()], y=data2['y']) # también puede ser a=data['a'].item()\n",
    "            )\n",
    "\n",
    "        return output\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset10 = synthetic_Dir_diffSize_NoBalanced_20percent_clasesMezcl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caso 11: dirigido, diferentes tamaños, NO balanceado (1%), clases separadas, features aplanadas\n",
    "\n",
    "Grafos iguales a los del caso 1, salvo que las features están aplanadas a 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class synthetic_Dir_diffSize_NoBalanced_1percent_clasesSep_flattened(Dataset):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    @property\n",
    "    def path(self):\n",
    "        return os.path.join(DATASET_FOLDER, \"syntheticGraphs\", self.__class__.__name__)\n",
    "    \n",
    "    def download(self):\n",
    "        os.makedirs(self.path)\n",
    "        \n",
    "        def generate_synthetic_graph_csbm(n_nodes, n_communities, n_features, edge_prob_matrix, node_feature_means,\\\n",
    "                                  n_infected, semilla, indice, feature_cov_matrix=None):\n",
    "            # Assign nodes to communities\n",
    "            np.random.seed(semilla*(indice+1))\n",
    "            indices = [np.random.randint(0,n_nodes) for i in range(n_infected)]\n",
    "            communities = np.array([int(j in indices) for j in range(n_nodes)])\n",
    "\n",
    "            # Generate node features\n",
    "            if feature_cov_matrix is None:\n",
    "                feature_cov_matrix = np.eye(n_features)\n",
    "            features = np.zeros((n_nodes, n_features))\n",
    "            for k in range(n_communities):\n",
    "                nodes_in_community = np.where(communities == k)[0]\n",
    "                features[nodes_in_community] = np.random.multivariate_normal(node_feature_means[k], feature_cov_matrix,\\\n",
    "                                                                             len(nodes_in_community))\n",
    "\n",
    "            # Compute community membership probabilities based on node features\n",
    "            community_membership_probs = softmax(features @ node_feature_means.T, axis=1)\n",
    "\n",
    "            # Generate edges based on community membership probabilities\n",
    "            adjacency_matrix = np.zeros((n_nodes, n_nodes))\n",
    "            for i in range(n_nodes):\n",
    "                for j in range(n_nodes):\n",
    "                    if i == j:\n",
    "                        continue\n",
    "                    community_i = communities[i]\n",
    "                    community_j = communities[j]\n",
    "                    edge_prob = edge_prob_matrix[community_i, community_j] * community_membership_probs[i, community_j] * community_membership_probs[j, community_i]\n",
    "                    adjacency_matrix[i, j] = np.random.binomial(1, edge_prob)\n",
    "\n",
    "            labels = tf.keras.utils.to_categorical(communities)\n",
    "            adjacency_matrix = sparse.csr_matrix(adjacency_matrix)\n",
    "            return Graph(x=np.ones((n_nodes, n_features)), a=adjacency_matrix, y=labels)\n",
    "\n",
    "        \n",
    "        n_graphs = 10\n",
    "        n_nodes = [25, 50, 100, 200, 400, 800, 1600, 3200, 6400, 12800]\n",
    "        n_features = 2\n",
    "        n_classes = 2\n",
    "        n_infected = [round((1/100)*n_nodes[i]) if (1/100)*n_nodes[i]>=1  else 1 for i in range(len(n_nodes))]\n",
    "        # Probability matrix for edges between communities\n",
    "        edge_prob_matrix = np.array([\n",
    "                                        [0.8, 0.2],\n",
    "                                        [0.3, 0.7]\n",
    "                                    ])\n",
    "        # Node feature means for each community\n",
    "        node_feature_means = np.array([\n",
    "                                        [2, 1], #, 0, 0, 0],\n",
    "                                        [1, 2] #, 0, 0, 0]\n",
    "                                    ])\n",
    "        \n",
    "        semillas = [123, 234, 345, 456, 567, 678, 789, 321, 654, 987]\n",
    "        \n",
    "        # Bien separadas las clases:\n",
    "        graphs1 = [generate_synthetic_graph_csbm(n_nodes[i], n_classes, n_features, edge_prob_matrix, node_feature_means, n_infected[i], semillas[i], 0, feature_cov_matrix=None) for i in range(n_graphs)]\n",
    "        for j in range(10):\n",
    "            filename = os.path.join(self.path, f'graph_Dir_NoBalanced_{n_infected[j]}a{n_nodes[j]}_clasesSep_0{j}_flattened.npz')\n",
    "            np.savez(filename, x=graphs1[j].x, a=graphs1[j].a, y=graphs1[j].y)\n",
    "\n",
    "        # Free memory\n",
    "        del graphs1\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "    def read(self):\n",
    "        # We must return a list of Graph objects\n",
    "        output = []\n",
    "\n",
    "        n_nodes = [25, 50, 100, 200, 400, 800, 1600, 3200, 6400, 12800]\n",
    "        n_infected = [round((1/100)*n_nodes[i]) if (1/100)*n_nodes[i]>=1  else 1 for i in range(len(n_nodes))]\n",
    "        \n",
    "        for j in range(10):\n",
    "            data1 = np.load(os.path.join(self.path, f'graph_Dir_NoBalanced_{n_infected[j]}a{n_nodes[j]}_clasesSep_0{j}_flattened.npz'), allow_pickle=True)\n",
    "            output.append(\n",
    "                Graph(x=data1['x'], a=data1['a'][()], y=data1['y']) # también puede ser a=data['a'].item()\n",
    "            )\n",
    "\n",
    "        return output\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset11 = synthetic_Dir_diffSize_NoBalanced_1percent_clasesSep_flattened()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caso 12: dirigido, diferentes tamaños, NO balanceado (1%), clases mezcladas, features aplanadas\n",
    "\n",
    "Grafos iguales a los del caso 2, salvo que las features están aplanadas a 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class synthetic_Dir_diffSize_NoBalanced_1percent_clasesMezcl_flattened(Dataset):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    @property\n",
    "    def path(self):\n",
    "        return os.path.join(DATASET_FOLDER, \"syntheticGraphs\", self.__class__.__name__)\n",
    "    \n",
    "    def download(self):\n",
    "        os.makedirs(self.path)\n",
    "        \n",
    "        def generate_synthetic_graph_csbm(n_nodes, n_communities, n_features, edge_prob_matrix, node_feature_means,\\\n",
    "                                  n_infected, semilla, indice, feature_cov_matrix=None):\n",
    "            # Assign nodes to communities\n",
    "            np.random.seed(semilla*(indice+1))\n",
    "            indices = [np.random.randint(0,n_nodes) for i in range(n_infected)]\n",
    "            communities = np.array([int(j in indices) for j in range(n_nodes)])\n",
    "\n",
    "            # Generate node features\n",
    "            if feature_cov_matrix is None:\n",
    "                feature_cov_matrix = np.eye(n_features)\n",
    "            features = np.zeros((n_nodes, n_features))\n",
    "            for k in range(n_communities):\n",
    "                nodes_in_community = np.where(communities == k)[0]\n",
    "                features[nodes_in_community] = np.random.multivariate_normal(node_feature_means[k], feature_cov_matrix,\\\n",
    "                                                                             len(nodes_in_community))\n",
    "\n",
    "            # Compute community membership probabilities based on node features\n",
    "            community_membership_probs = softmax(features @ node_feature_means.T, axis=1)\n",
    "\n",
    "            # Generate edges based on community membership probabilities\n",
    "            adjacency_matrix = np.zeros((n_nodes, n_nodes))\n",
    "            for i in range(n_nodes):\n",
    "                for j in range(n_nodes):\n",
    "                    if i == j:\n",
    "                        continue\n",
    "                    community_i = communities[i]\n",
    "                    community_j = communities[j]\n",
    "                    edge_prob = edge_prob_matrix[community_i, community_j] * community_membership_probs[i, community_j] * community_membership_probs[j, community_i]\n",
    "                    adjacency_matrix[i, j] = np.random.binomial(1, edge_prob)\n",
    "\n",
    "            labels = tf.keras.utils.to_categorical(communities)\n",
    "            adjacency_matrix = sparse.csr_matrix(adjacency_matrix)\n",
    "            return Graph(x=np.ones((n_nodes, n_features)), a=adjacency_matrix, y=labels)\n",
    "\n",
    "        \n",
    "        n_graphs = 10\n",
    "        n_nodes = [25, 50, 100, 200, 400, 800, 1600, 3200, 6400, 12800]\n",
    "        n_features = 2\n",
    "        n_classes = 2\n",
    "        n_infected = [round((1/100)*n_nodes[i]) if (1/100)*n_nodes[i]>=1  else 1 for i in range(len(n_nodes))]\n",
    "        # Probability matrix for edges between communities\n",
    "        edge_prob_matrix = np.array([\n",
    "                                    [0.5, 0.5],\n",
    "                                    [0.5, 0.5]\n",
    "                            ])\n",
    "        # Node feature means for each community\n",
    "        node_feature_means = np.array([\n",
    "                                        [1, 1], #, 0, 0, 0],\n",
    "                                        [1, 1] #, 0, 0, 0]\n",
    "                                    ])\n",
    "        \n",
    "        semillas = [123, 234, 345, 456, 567, 678, 789, 321, 654, 987]\n",
    "        \n",
    "        # Clases un poco más juntas:\n",
    "        graphs2 = [generate_synthetic_graph_csbm(n_nodes[i], n_classes, n_features, edge_prob_matrix, node_feature_means, n_infected[i], semillas[i], 1, feature_cov_matrix=None) for i in range(n_graphs)]\n",
    "        for j in range(10):\n",
    "            filename = os.path.join(self.path, f'graph_Dir_NoBalanced_{n_infected[j]}a{n_nodes[j]}_clasesMezcl_2{j}_flattened.npz')\n",
    "            np.savez(filename, x=graphs2[j].x, a=graphs2[j].a, y=graphs2[j].y)\n",
    "\n",
    "        # Free memory\n",
    "        del graphs2\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "    def read(self):\n",
    "        # We must return a list of Graph objects\n",
    "        output = []\n",
    "\n",
    "        n_nodes = [25, 50, 100, 200, 400, 800, 1600, 3200, 6400, 12800]\n",
    "        n_infected = [round((1/100)*n_nodes[i]) if (1/100)*n_nodes[i]>=1  else 1 for i in range(len(n_nodes))]\n",
    "        \n",
    "        for j in range(10):\n",
    "            data2 = np.load(os.path.join(self.path, f'graph_Dir_NoBalanced_{n_infected[j]}a{n_nodes[j]}_clasesMezcl_2{j}_flattened.npz'), allow_pickle=True)\n",
    "            output.append(\n",
    "                Graph(x=data2['x'], a=data2['a'][()], y=data2['y']) # también puede ser a=data['a'].item()\n",
    "            )\n",
    "\n",
    "        return output\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset12 = synthetic_Dir_diffSize_NoBalanced_1percent_clasesMezcl_flattened()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caso 13: dirigido, diferentes tamaños, NO balanceado (2%), clases separadas, features aplanadas\n",
    "\n",
    "Grafos iguales a los del caso 3, salvo que las features están aplanadas a 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class synthetic_Dir_diffSize_NoBalanced_2percent_clasesSep_flattened(Dataset):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    @property\n",
    "    def path(self):\n",
    "        return os.path.join(DATASET_FOLDER, \"syntheticGraphs\", self.__class__.__name__)\n",
    "    \n",
    "    def download(self):\n",
    "        os.makedirs(self.path)\n",
    "        \n",
    "        def generate_synthetic_graph_csbm(n_nodes, n_communities, n_features, edge_prob_matrix, node_feature_means,\\\n",
    "                                  n_infected, semilla, indice, feature_cov_matrix=None):\n",
    "            # Assign nodes to communities\n",
    "            np.random.seed(semilla*(indice+1))\n",
    "            indices = [np.random.randint(0,n_nodes) for i in range(n_infected)]\n",
    "            communities = np.array([int(j in indices) for j in range(n_nodes)])\n",
    "\n",
    "            # Generate node features\n",
    "            if feature_cov_matrix is None:\n",
    "                feature_cov_matrix = np.eye(n_features)\n",
    "            features = np.zeros((n_nodes, n_features))\n",
    "            for k in range(n_communities):\n",
    "                nodes_in_community = np.where(communities == k)[0]\n",
    "                features[nodes_in_community] = np.random.multivariate_normal(node_feature_means[k], feature_cov_matrix,\\\n",
    "                                                                             len(nodes_in_community))\n",
    "\n",
    "            # Compute community membership probabilities based on node features\n",
    "            community_membership_probs = softmax(features @ node_feature_means.T, axis=1)\n",
    "\n",
    "            # Generate edges based on community membership probabilities\n",
    "            adjacency_matrix = np.zeros((n_nodes, n_nodes))\n",
    "            for i in range(n_nodes):\n",
    "                for j in range(n_nodes):\n",
    "                    if i == j:\n",
    "                        continue\n",
    "                    community_i = communities[i]\n",
    "                    community_j = communities[j]\n",
    "                    edge_prob = edge_prob_matrix[community_i, community_j] * community_membership_probs[i, community_j] * community_membership_probs[j, community_i]\n",
    "                    adjacency_matrix[i, j] = np.random.binomial(1, edge_prob)\n",
    "\n",
    "            labels = tf.keras.utils.to_categorical(communities)\n",
    "            adjacency_matrix = sparse.csr_matrix(adjacency_matrix)\n",
    "            return Graph(x=np.ones((n_nodes, n_features)), a=adjacency_matrix, y=labels)\n",
    "\n",
    "        \n",
    "        n_graphs = 10\n",
    "        n_nodes = [25, 50, 100, 200, 400, 800, 1600, 3200, 6400, 12800]\n",
    "        n_features = 2\n",
    "        n_classes = 2\n",
    "        n_infected = [round((2/100)*n_nodes[i]) if (2/100)*n_nodes[i]>=1  else 1 for i in range(len(n_nodes))]\n",
    "        # Probability matrix for edges between communities\n",
    "        edge_prob_matrix = np.array([\n",
    "                                        [0.8, 0.2],\n",
    "                                        [0.3, 0.7]\n",
    "                                    ])\n",
    "        # Node feature means for each community\n",
    "        node_feature_means = np.array([\n",
    "                                        [2, 1], #, 0, 0, 0],\n",
    "                                        [1, 2] #, 0, 0, 0]\n",
    "                                    ])\n",
    "        \n",
    "        semillas = [123, 234, 345, 456, 567, 678, 789, 321, 654, 987]\n",
    "        \n",
    "        # Bien separadas las clases:\n",
    "        graphs1 = [generate_synthetic_graph_csbm(n_nodes[i], n_classes, n_features, edge_prob_matrix, node_feature_means, n_infected[i], semillas[i], 0, feature_cov_matrix=None) for i in range(n_graphs)]\n",
    "        for j in range(10):\n",
    "            filename = os.path.join(self.path, f'graph_Dir_NoBalanced_{n_infected[j]}a{n_nodes[j]}_clasesSep_0{j}_flattened.npz')\n",
    "            np.savez(filename, x=graphs1[j].x, a=graphs1[j].a, y=graphs1[j].y)\n",
    "\n",
    "        # Free memory\n",
    "        del graphs1\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "    def read(self):\n",
    "        # We must return a list of Graph objects\n",
    "        output = []\n",
    "\n",
    "        n_nodes = [25, 50, 100, 200, 400, 800, 1600, 3200, 6400, 12800]\n",
    "        n_infected = [round((2/100)*n_nodes[i]) if (2/100)*n_nodes[i]>=1  else 1 for i in range(len(n_nodes))]\n",
    "        \n",
    "        for j in range(10):\n",
    "            data1 = np.load(os.path.join(self.path, f'graph_Dir_NoBalanced_{n_infected[j]}a{n_nodes[j]}_clasesSep_0{j}_flattened.npz'), allow_pickle=True)\n",
    "            output.append(\n",
    "                Graph(x=data1['x'], a=data1['a'][()], y=data1['y']) # también puede ser a=data['a'].item()\n",
    "            )\n",
    "\n",
    "        return output\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset13 = synthetic_Dir_diffSize_NoBalanced_2percent_clasesSep_flattened()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caso 14: dirigido, diferentes tamaños, NO balanceado (2%), clases mezcladas, features aplanadas\n",
    "\n",
    "Grafos iguales a los del caso 4, salvo que las features están aplanadas a 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class synthetic_Dir_diffSize_NoBalanced_2percent_clasesMezcl_flattened(Dataset):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    @property\n",
    "    def path(self):\n",
    "        return os.path.join(DATASET_FOLDER, \"syntheticGraphs\", self.__class__.__name__)\n",
    "    \n",
    "    def download(self):\n",
    "        os.makedirs(self.path)\n",
    "        \n",
    "        def generate_synthetic_graph_csbm(n_nodes, n_communities, n_features, edge_prob_matrix, node_feature_means,\\\n",
    "                                  n_infected, semilla, indice, feature_cov_matrix=None):\n",
    "            # Assign nodes to communities\n",
    "            np.random.seed(semilla*(indice+1))\n",
    "            indices = [np.random.randint(0,n_nodes) for i in range(n_infected)]\n",
    "            communities = np.array([int(j in indices) for j in range(n_nodes)])\n",
    "\n",
    "            # Generate node features\n",
    "            if feature_cov_matrix is None:\n",
    "                feature_cov_matrix = np.eye(n_features)\n",
    "            features = np.zeros((n_nodes, n_features))\n",
    "            for k in range(n_communities):\n",
    "                nodes_in_community = np.where(communities == k)[0]\n",
    "                features[nodes_in_community] = np.random.multivariate_normal(node_feature_means[k], feature_cov_matrix,\\\n",
    "                                                                             len(nodes_in_community))\n",
    "\n",
    "            # Compute community membership probabilities based on node features\n",
    "            community_membership_probs = softmax(features @ node_feature_means.T, axis=1)\n",
    "\n",
    "            # Generate edges based on community membership probabilities\n",
    "            adjacency_matrix = np.zeros((n_nodes, n_nodes))\n",
    "            for i in range(n_nodes):\n",
    "                for j in range(n_nodes):\n",
    "                    if i == j:\n",
    "                        continue\n",
    "                    community_i = communities[i]\n",
    "                    community_j = communities[j]\n",
    "                    edge_prob = edge_prob_matrix[community_i, community_j] * community_membership_probs[i, community_j] * community_membership_probs[j, community_i]\n",
    "                    adjacency_matrix[i, j] = np.random.binomial(1, edge_prob)\n",
    "\n",
    "            labels = tf.keras.utils.to_categorical(communities)\n",
    "            adjacency_matrix = sparse.csr_matrix(adjacency_matrix)\n",
    "            return Graph(x=np.ones((n_nodes, n_features)), a=adjacency_matrix, y=labels)\n",
    "\n",
    "        \n",
    "        n_graphs = 10\n",
    "        n_nodes = [25, 50, 100, 200, 400, 800, 1600, 3200, 6400, 12800]\n",
    "        n_features = 2\n",
    "        n_classes = 2\n",
    "        n_infected = [round((2/100)*n_nodes[i]) if (2/100)*n_nodes[i]>=1  else 1 for i in range(len(n_nodes))]\n",
    "        # Probability matrix for edges between communities\n",
    "        edge_prob_matrix = np.array([\n",
    "                                    [0.5, 0.5],\n",
    "                                    [0.5, 0.5]\n",
    "                            ])\n",
    "        # Node feature means for each community\n",
    "        node_feature_means = np.array([\n",
    "                                        [1, 1], #, 0, 0, 0],\n",
    "                                        [1, 1] #, 0, 0, 0]\n",
    "                                    ])\n",
    "        \n",
    "        semillas = [123, 234, 345, 456, 567, 678, 789, 321, 654, 987]\n",
    "        \n",
    "        # Clases un poco más juntas:\n",
    "        graphs2 = [generate_synthetic_graph_csbm(n_nodes[i], n_classes, n_features, edge_prob_matrix, node_feature_means, n_infected[i], semillas[i], 1, feature_cov_matrix=None) for i in range(n_graphs)]\n",
    "        for j in range(10):\n",
    "            filename = os.path.join(self.path, f'graph_Dir_NoBalanced_{n_infected[j]}a{n_nodes[j]}_clasesMezcl_2{j}_flattened.npz')\n",
    "            np.savez(filename, x=graphs2[j].x, a=graphs2[j].a, y=graphs2[j].y)\n",
    "\n",
    "        # Free memory\n",
    "        del graphs2\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "    def read(self):\n",
    "        # We must return a list of Graph objects\n",
    "        output = []\n",
    "\n",
    "        n_nodes = [25, 50, 100, 200, 400, 800, 1600, 3200, 6400, 12800]\n",
    "        n_infected = [round((2/100)*n_nodes[i]) if (2/100)*n_nodes[i]>=1  else 1 for i in range(len(n_nodes))]\n",
    "        \n",
    "        for j in range(10):\n",
    "            data2 = np.load(os.path.join(self.path, f'graph_Dir_NoBalanced_{n_infected[j]}a{n_nodes[j]}_clasesMezcl_2{j}_flattened.npz'), allow_pickle=True)\n",
    "            output.append(\n",
    "                Graph(x=data2['x'], a=data2['a'][()], y=data2['y']) # también puede ser a=data['a'].item()\n",
    "            )\n",
    "\n",
    "        return output\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset14 = synthetic_Dir_diffSize_NoBalanced_2percent_clasesMezcl_flattened()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caso 15: dirigido, diferentes tamaños, NO balanceado (5%), clases separadas, features aplanadas\n",
    "\n",
    "Grafos iguales a los del caso 5, salvo que las features están aplanadas a 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class synthetic_Dir_diffSize_NoBalanced_5percent_clasesSep_flattened(Dataset):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    @property\n",
    "    def path(self):\n",
    "        return os.path.join(DATASET_FOLDER, \"syntheticGraphs\", self.__class__.__name__)\n",
    "    \n",
    "    def download(self):\n",
    "        os.makedirs(self.path)\n",
    "        \n",
    "        def generate_synthetic_graph_csbm(n_nodes, n_communities, n_features, edge_prob_matrix, node_feature_means,\\\n",
    "                                  n_infected, semilla, indice, feature_cov_matrix=None):\n",
    "            # Assign nodes to communities\n",
    "            np.random.seed(semilla*(indice+1))\n",
    "            indices = [np.random.randint(0,n_nodes) for i in range(n_infected)]\n",
    "            communities = np.array([int(j in indices) for j in range(n_nodes)])\n",
    "\n",
    "            # Generate node features\n",
    "            if feature_cov_matrix is None:\n",
    "                feature_cov_matrix = np.eye(n_features)\n",
    "            features = np.zeros((n_nodes, n_features))\n",
    "            for k in range(n_communities):\n",
    "                nodes_in_community = np.where(communities == k)[0]\n",
    "                features[nodes_in_community] = np.random.multivariate_normal(node_feature_means[k], feature_cov_matrix,\\\n",
    "                                                                             len(nodes_in_community))\n",
    "\n",
    "            # Compute community membership probabilities based on node features\n",
    "            community_membership_probs = softmax(features @ node_feature_means.T, axis=1)\n",
    "\n",
    "            # Generate edges based on community membership probabilities\n",
    "            adjacency_matrix = np.zeros((n_nodes, n_nodes))\n",
    "            for i in range(n_nodes):\n",
    "                for j in range(n_nodes):\n",
    "                    if i == j:\n",
    "                        continue\n",
    "                    community_i = communities[i]\n",
    "                    community_j = communities[j]\n",
    "                    edge_prob = edge_prob_matrix[community_i, community_j] * community_membership_probs[i, community_j] * community_membership_probs[j, community_i]\n",
    "                    adjacency_matrix[i, j] = np.random.binomial(1, edge_prob)\n",
    "\n",
    "            labels = tf.keras.utils.to_categorical(communities)\n",
    "            adjacency_matrix = sparse.csr_matrix(adjacency_matrix)\n",
    "            return Graph(x=np.ones((n_nodes, n_features)), a=adjacency_matrix, y=labels)\n",
    "\n",
    "        \n",
    "        n_graphs = 10\n",
    "        n_nodes = [25, 50, 100, 200, 400, 800, 1600, 3200, 6400, 12800]\n",
    "        n_features = 2\n",
    "        n_classes = 2\n",
    "        n_infected = [round((5/100)*n_nodes[i]) if (5/100)*n_nodes[i]>=1  else 1 for i in range(len(n_nodes))]\n",
    "        # Probability matrix for edges between communities\n",
    "        edge_prob_matrix = np.array([\n",
    "                                        [0.8, 0.2],\n",
    "                                        [0.3, 0.7]\n",
    "                                    ])\n",
    "        # Node feature means for each community\n",
    "        node_feature_means = np.array([\n",
    "                                        [2, 1], #, 0, 0, 0],\n",
    "                                        [1, 2] #, 0, 0, 0]\n",
    "                                    ])\n",
    "        \n",
    "        semillas = [123, 234, 345, 456, 567, 678, 789, 321, 654, 987]\n",
    "        \n",
    "        # Bien separadas las clases:\n",
    "        graphs1 = [generate_synthetic_graph_csbm(n_nodes[i], n_classes, n_features, edge_prob_matrix, node_feature_means, n_infected[i], semillas[i], 0, feature_cov_matrix=None) for i in range(n_graphs)]\n",
    "        for j in range(10):\n",
    "            filename = os.path.join(self.path, f'graph_Dir_NoBalanced_{n_infected[j]}a{n_nodes[j]}_clasesSep_0{j}_flattened.npz')\n",
    "            np.savez(filename, x=graphs1[j].x, a=graphs1[j].a, y=graphs1[j].y)\n",
    "\n",
    "        # Free memory\n",
    "        del graphs1\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "    def read(self):\n",
    "        # We must return a list of Graph objects\n",
    "        output = []\n",
    "\n",
    "        n_nodes = [25, 50, 100, 200, 400, 800, 1600, 3200, 6400, 12800]\n",
    "        n_infected = [round((5/100)*n_nodes[i]) if (5/100)*n_nodes[i]>=1  else 1 for i in range(len(n_nodes))]\n",
    "        \n",
    "        for j in range(10):\n",
    "            data1 = np.load(os.path.join(self.path, f'graph_Dir_NoBalanced_{n_infected[j]}a{n_nodes[j]}_clasesSep_0{j}_flattened.npz'), allow_pickle=True)\n",
    "            output.append(\n",
    "                Graph(x=data1['x'], a=data1['a'][()], y=data1['y']) # también puede ser a=data['a'].item()\n",
    "            )\n",
    "\n",
    "        return output\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset15 = synthetic_Dir_diffSize_NoBalanced_5percent_clasesSep_flattened()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caso 16: dirigido, diferentes tamaños, NO balanceado (5%), clases mezcladas, features aplanadas\n",
    "\n",
    "Grafos iguales a los del caso 6, salvo que las features están aplanadas a 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class synthetic_Dir_diffSize_NoBalanced_5percent_clasesMezcl_flattened(Dataset):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    @property\n",
    "    def path(self):\n",
    "        return os.path.join(DATASET_FOLDER, \"syntheticGraphs\", self.__class__.__name__)\n",
    "    \n",
    "    def download(self):\n",
    "        os.makedirs(self.path)\n",
    "        \n",
    "        def generate_synthetic_graph_csbm(n_nodes, n_communities, n_features, edge_prob_matrix, node_feature_means,\\\n",
    "                                  n_infected, semilla, indice, feature_cov_matrix=None):\n",
    "            # Assign nodes to communities\n",
    "            np.random.seed(semilla*(indice+1))\n",
    "            indices = [np.random.randint(0,n_nodes) for i in range(n_infected)]\n",
    "            communities = np.array([int(j in indices) for j in range(n_nodes)])\n",
    "\n",
    "            # Generate node features\n",
    "            if feature_cov_matrix is None:\n",
    "                feature_cov_matrix = np.eye(n_features)\n",
    "            features = np.zeros((n_nodes, n_features))\n",
    "            for k in range(n_communities):\n",
    "                nodes_in_community = np.where(communities == k)[0]\n",
    "                features[nodes_in_community] = np.random.multivariate_normal(node_feature_means[k], feature_cov_matrix,\\\n",
    "                                                                             len(nodes_in_community))\n",
    "\n",
    "            # Compute community membership probabilities based on node features\n",
    "            community_membership_probs = softmax(features @ node_feature_means.T, axis=1)\n",
    "\n",
    "            # Generate edges based on community membership probabilities\n",
    "            adjacency_matrix = np.zeros((n_nodes, n_nodes))\n",
    "            for i in range(n_nodes):\n",
    "                for j in range(n_nodes):\n",
    "                    if i == j:\n",
    "                        continue\n",
    "                    community_i = communities[i]\n",
    "                    community_j = communities[j]\n",
    "                    edge_prob = edge_prob_matrix[community_i, community_j] * community_membership_probs[i, community_j] * community_membership_probs[j, community_i]\n",
    "                    adjacency_matrix[i, j] = np.random.binomial(1, edge_prob)\n",
    "\n",
    "            labels = tf.keras.utils.to_categorical(communities)\n",
    "            adjacency_matrix = sparse.csr_matrix(adjacency_matrix)\n",
    "            return Graph(x=np.ones((n_nodes, n_features)), a=adjacency_matrix, y=labels)\n",
    "\n",
    "        \n",
    "        n_graphs = 10\n",
    "        n_nodes = [25, 50, 100, 200, 400, 800, 1600, 3200, 6400, 12800]\n",
    "        n_features = 2\n",
    "        n_classes = 2\n",
    "        n_infected = [round((5/100)*n_nodes[i]) if (5/100)*n_nodes[i]>=1  else 1 for i in range(len(n_nodes))]\n",
    "        # Probability matrix for edges between communities\n",
    "        edge_prob_matrix = np.array([\n",
    "                                    [0.5, 0.5],\n",
    "                                    [0.5, 0.5]\n",
    "                            ])\n",
    "        # Node feature means for each community\n",
    "        node_feature_means = np.array([\n",
    "                                        [1, 1], #, 0, 0, 0],\n",
    "                                        [1, 1] #, 0, 0, 0]\n",
    "                                    ])\n",
    "        \n",
    "        semillas = [123, 234, 345, 456, 567, 678, 789, 321, 654, 987]\n",
    "        \n",
    "        # Clases un poco más juntas:\n",
    "        graphs2 = [generate_synthetic_graph_csbm(n_nodes[i], n_classes, n_features, edge_prob_matrix, node_feature_means, n_infected[i], semillas[i], 1, feature_cov_matrix=None) for i in range(n_graphs)]\n",
    "        for j in range(10):\n",
    "            filename = os.path.join(self.path, f'graph_Dir_NoBalanced_{n_infected[j]}a{n_nodes[j]}_clasesMezcl_2{j}_flattened.npz')\n",
    "            np.savez(filename, x=graphs2[j].x, a=graphs2[j].a, y=graphs2[j].y)\n",
    "\n",
    "        # Free memory\n",
    "        del graphs2\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "    def read(self):\n",
    "        # We must return a list of Graph objects\n",
    "        output = []\n",
    "\n",
    "        n_nodes = [25, 50, 100, 200, 400, 800, 1600, 3200, 6400, 12800]\n",
    "        n_infected = [round((5/100)*n_nodes[i]) if (5/100)*n_nodes[i]>=1  else 1 for i in range(len(n_nodes))]\n",
    "        \n",
    "        for j in range(10):\n",
    "            data2 = np.load(os.path.join(self.path, f'graph_Dir_NoBalanced_{n_infected[j]}a{n_nodes[j]}_clasesMezcl_2{j}_flattened.npz'), allow_pickle=True)\n",
    "            output.append(\n",
    "                Graph(x=data2['x'], a=data2['a'][()], y=data2['y']) # también puede ser a=data['a'].item()\n",
    "            )\n",
    "\n",
    "        return output\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset16 = synthetic_Dir_diffSize_NoBalanced_5percent_clasesMezcl_flattened()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caso 17: dirigido, diferentes tamaños, NO balanceado (10%), clases separadas, features aplanadas\n",
    "\n",
    "Grafos iguales a los del caso 7, salvo que las features están aplanadas a 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class synthetic_Dir_diffSize_NoBalanced_10percent_clasesSep_flattened(Dataset):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    @property\n",
    "    def path(self):\n",
    "        return os.path.join(DATASET_FOLDER, \"syntheticGraphs\", self.__class__.__name__)\n",
    "    \n",
    "    def download(self):\n",
    "        os.makedirs(self.path)\n",
    "        \n",
    "        def generate_synthetic_graph_csbm(n_nodes, n_communities, n_features, edge_prob_matrix, node_feature_means,\\\n",
    "                                  n_infected, semilla, indice, feature_cov_matrix=None):\n",
    "            # Assign nodes to communities\n",
    "            np.random.seed(semilla*(indice+1))\n",
    "            indices = [np.random.randint(0,n_nodes) for i in range(n_infected)]\n",
    "            communities = np.array([int(j in indices) for j in range(n_nodes)])\n",
    "\n",
    "            # Generate node features\n",
    "            if feature_cov_matrix is None:\n",
    "                feature_cov_matrix = np.eye(n_features)\n",
    "            features = np.zeros((n_nodes, n_features))\n",
    "            for k in range(n_communities):\n",
    "                nodes_in_community = np.where(communities == k)[0]\n",
    "                features[nodes_in_community] = np.random.multivariate_normal(node_feature_means[k], feature_cov_matrix,\\\n",
    "                                                                             len(nodes_in_community))\n",
    "\n",
    "            # Compute community membership probabilities based on node features\n",
    "            community_membership_probs = softmax(features @ node_feature_means.T, axis=1)\n",
    "\n",
    "            # Generate edges based on community membership probabilities\n",
    "            adjacency_matrix = np.zeros((n_nodes, n_nodes))\n",
    "            for i in range(n_nodes):\n",
    "                for j in range(n_nodes):\n",
    "                    if i == j:\n",
    "                        continue\n",
    "                    community_i = communities[i]\n",
    "                    community_j = communities[j]\n",
    "                    edge_prob = edge_prob_matrix[community_i, community_j] * community_membership_probs[i, community_j] * community_membership_probs[j, community_i]\n",
    "                    adjacency_matrix[i, j] = np.random.binomial(1, edge_prob)\n",
    "\n",
    "            labels = tf.keras.utils.to_categorical(communities)\n",
    "            adjacency_matrix = sparse.csr_matrix(adjacency_matrix)\n",
    "            return Graph(x=np.ones((n_nodes, n_features)), a=adjacency_matrix, y=labels)\n",
    "\n",
    "        \n",
    "        n_graphs = 10\n",
    "        n_nodes = [25, 50, 100, 200, 400, 800, 1600, 3200, 6400, 12800]\n",
    "        n_features = 2\n",
    "        n_classes = 2\n",
    "        n_infected = [round((10/100)*n_nodes[i]) if (10/100)*n_nodes[i]>=1  else 1 for i in range(len(n_nodes))]\n",
    "        # Probability matrix for edges between communities\n",
    "        edge_prob_matrix = np.array([\n",
    "                                        [0.8, 0.2],\n",
    "                                        [0.3, 0.7]\n",
    "                                    ])\n",
    "        # Node feature means for each community\n",
    "        node_feature_means = np.array([\n",
    "                                        [2, 1], #, 0, 0, 0],\n",
    "                                        [1, 2] #, 0, 0, 0]\n",
    "                                    ])\n",
    "        \n",
    "        semillas = [123, 234, 345, 456, 567, 678, 789, 321, 654, 987]\n",
    "        \n",
    "        # Bien separadas las clases:\n",
    "        graphs1 = [generate_synthetic_graph_csbm(n_nodes[i], n_classes, n_features, edge_prob_matrix, node_feature_means, n_infected[i], semillas[i], 0, feature_cov_matrix=None) for i in range(n_graphs)]\n",
    "        for j in range(10):\n",
    "            filename = os.path.join(self.path, f'graph_Dir_NoBalanced_{n_infected[j]}a{n_nodes[j]}_clasesSep_0{j}_flattened.npz')\n",
    "            np.savez(filename, x=graphs1[j].x, a=graphs1[j].a, y=graphs1[j].y)\n",
    "\n",
    "        # Free memory\n",
    "        del graphs1\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "    def read(self):\n",
    "        # We must return a list of Graph objects\n",
    "        output = []\n",
    "\n",
    "        n_nodes = [25, 50, 100, 200, 400, 800, 1600, 3200, 6400, 12800]\n",
    "        n_infected = [round((10/100)*n_nodes[i]) if (10/100)*n_nodes[i]>=1  else 1 for i in range(len(n_nodes))]\n",
    "        \n",
    "        for j in range(10):\n",
    "            data1 = np.load(os.path.join(self.path, f'graph_Dir_NoBalanced_{n_infected[j]}a{n_nodes[j]}_clasesSep_0{j}_flattened.npz'), allow_pickle=True)\n",
    "            output.append(\n",
    "                Graph(x=data1['x'], a=data1['a'][()], y=data1['y']) # también puede ser a=data['a'].item()\n",
    "            )\n",
    "\n",
    "        return output\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset17 = synthetic_Dir_diffSize_NoBalanced_10percent_clasesSep_flattened()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caso 18: dirigido, diferentes tamaños, NO balanceado (10%), clases mezcladas, features aplanadas\n",
    "\n",
    "Grafos iguales a los del caso 8, salvo que las features están aplanadas a 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class synthetic_Dir_diffSize_NoBalanced_10percent_clasesMezcl_flattened(Dataset):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    @property\n",
    "    def path(self):\n",
    "        return os.path.join(DATASET_FOLDER, \"syntheticGraphs\", self.__class__.__name__)\n",
    "    \n",
    "    def download(self):\n",
    "        os.makedirs(self.path)\n",
    "        \n",
    "        def generate_synthetic_graph_csbm(n_nodes, n_communities, n_features, edge_prob_matrix, node_feature_means,\\\n",
    "                                  n_infected, semilla, indice, feature_cov_matrix=None):\n",
    "            # Assign nodes to communities\n",
    "            np.random.seed(semilla*(indice+1))\n",
    "            indices = [np.random.randint(0,n_nodes) for i in range(n_infected)]\n",
    "            communities = np.array([int(j in indices) for j in range(n_nodes)])\n",
    "\n",
    "            # Generate node features\n",
    "            if feature_cov_matrix is None:\n",
    "                feature_cov_matrix = np.eye(n_features)\n",
    "            features = np.zeros((n_nodes, n_features))\n",
    "            for k in range(n_communities):\n",
    "                nodes_in_community = np.where(communities == k)[0]\n",
    "                features[nodes_in_community] = np.random.multivariate_normal(node_feature_means[k], feature_cov_matrix,\\\n",
    "                                                                             len(nodes_in_community))\n",
    "\n",
    "            # Compute community membership probabilities based on node features\n",
    "            community_membership_probs = softmax(features @ node_feature_means.T, axis=1)\n",
    "\n",
    "            # Generate edges based on community membership probabilities\n",
    "            adjacency_matrix = np.zeros((n_nodes, n_nodes))\n",
    "            for i in range(n_nodes):\n",
    "                for j in range(n_nodes):\n",
    "                    if i == j:\n",
    "                        continue\n",
    "                    community_i = communities[i]\n",
    "                    community_j = communities[j]\n",
    "                    edge_prob = edge_prob_matrix[community_i, community_j] * community_membership_probs[i, community_j] * community_membership_probs[j, community_i]\n",
    "                    adjacency_matrix[i, j] = np.random.binomial(1, edge_prob)\n",
    "\n",
    "            labels = tf.keras.utils.to_categorical(communities)\n",
    "            adjacency_matrix = sparse.csr_matrix(adjacency_matrix)\n",
    "            return Graph(x=np.ones((n_nodes, n_features)), a=adjacency_matrix, y=labels)\n",
    "\n",
    "        \n",
    "        n_graphs = 10\n",
    "        n_nodes = [25, 50, 100, 200, 400, 800, 1600, 3200, 6400, 12800]\n",
    "        n_features = 2\n",
    "        n_classes = 2\n",
    "        n_infected = [round((10/100)*n_nodes[i]) if (10/100)*n_nodes[i]>=1  else 1 for i in range(len(n_nodes))]\n",
    "        # Probability matrix for edges between communities\n",
    "        edge_prob_matrix = np.array([\n",
    "                                    [0.5, 0.5],\n",
    "                                    [0.5, 0.5]\n",
    "                            ])\n",
    "        # Node feature means for each community\n",
    "        node_feature_means = np.array([\n",
    "                                        [1, 1], #, 0, 0, 0],\n",
    "                                        [1, 1] #, 0, 0, 0]\n",
    "                                    ])\n",
    "        \n",
    "        semillas = [123, 234, 345, 456, 567, 678, 789, 321, 654, 987]\n",
    "        \n",
    "        # Clases un poco más juntas:\n",
    "        graphs2 = [generate_synthetic_graph_csbm(n_nodes[i], n_classes, n_features, edge_prob_matrix, node_feature_means, n_infected[i], semillas[i], 1, feature_cov_matrix=None) for i in range(n_graphs)]\n",
    "        for j in range(10):\n",
    "            filename = os.path.join(self.path, f'graph_Dir_NoBalanced_{n_infected[j]}a{n_nodes[j]}_clasesMezcl_2{j}_flattened.npz')\n",
    "            np.savez(filename, x=graphs2[j].x, a=graphs2[j].a, y=graphs2[j].y)\n",
    "\n",
    "        # Free memory\n",
    "        del graphs2\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "    def read(self):\n",
    "        # We must return a list of Graph objects\n",
    "        output = []\n",
    "\n",
    "        n_nodes = [25, 50, 100, 200, 400, 800, 1600, 3200, 6400, 12800]\n",
    "        n_infected = [round((10/100)*n_nodes[i]) if (10/100)*n_nodes[i]>=1  else 1 for i in range(len(n_nodes))]\n",
    "        \n",
    "        for j in range(10):\n",
    "            data2 = np.load(os.path.join(self.path, f'graph_Dir_NoBalanced_{n_infected[j]}a{n_nodes[j]}_clasesMezcl_2{j}_flattened.npz'), allow_pickle=True)\n",
    "            output.append(\n",
    "                Graph(x=data2['x'], a=data2['a'][()], y=data2['y']) # también puede ser a=data['a'].item()\n",
    "            )\n",
    "\n",
    "        return output\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset18 = synthetic_Dir_diffSize_NoBalanced_10percent_clasesMezcl_flattened()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caso 19: dirigido, diferentes tamaños, NO balanceado (20%), clases separadas, features aplanadas\n",
    "\n",
    "Grafos iguales a los del caso 9, salvo que las features están aplanadas a 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class synthetic_Dir_diffSize_NoBalanced_20percent_clasesSep_flattened(Dataset):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    @property\n",
    "    def path(self):\n",
    "        return os.path.join(DATASET_FOLDER, \"syntheticGraphs\", self.__class__.__name__)\n",
    "    \n",
    "    def download(self):\n",
    "        os.makedirs(self.path)\n",
    "        \n",
    "        def generate_synthetic_graph_csbm(n_nodes, n_communities, n_features, edge_prob_matrix, node_feature_means,\\\n",
    "                                  n_infected, semilla, indice, feature_cov_matrix=None):\n",
    "            # Assign nodes to communities\n",
    "            np.random.seed(semilla*(indice+1))\n",
    "            indices = [np.random.randint(0,n_nodes) for i in range(n_infected)]\n",
    "            communities = np.array([int(j in indices) for j in range(n_nodes)])\n",
    "\n",
    "            # Generate node features\n",
    "            if feature_cov_matrix is None:\n",
    "                feature_cov_matrix = np.eye(n_features)\n",
    "            features = np.zeros((n_nodes, n_features))\n",
    "            for k in range(n_communities):\n",
    "                nodes_in_community = np.where(communities == k)[0]\n",
    "                features[nodes_in_community] = np.random.multivariate_normal(node_feature_means[k], feature_cov_matrix,\\\n",
    "                                                                             len(nodes_in_community))\n",
    "\n",
    "            # Compute community membership probabilities based on node features\n",
    "            community_membership_probs = softmax(features @ node_feature_means.T, axis=1)\n",
    "\n",
    "            # Generate edges based on community membership probabilities\n",
    "            adjacency_matrix = np.zeros((n_nodes, n_nodes))\n",
    "            for i in range(n_nodes):\n",
    "                for j in range(n_nodes):\n",
    "                    if i == j:\n",
    "                        continue\n",
    "                    community_i = communities[i]\n",
    "                    community_j = communities[j]\n",
    "                    edge_prob = edge_prob_matrix[community_i, community_j] * community_membership_probs[i, community_j] * community_membership_probs[j, community_i]\n",
    "                    adjacency_matrix[i, j] = np.random.binomial(1, edge_prob)\n",
    "\n",
    "            labels = tf.keras.utils.to_categorical(communities)\n",
    "            adjacency_matrix = sparse.csr_matrix(adjacency_matrix)\n",
    "            return Graph(x=np.ones((n_nodes, n_features)), a=adjacency_matrix, y=labels)\n",
    "\n",
    "        \n",
    "        n_graphs = 10\n",
    "        n_nodes = [25, 50, 100, 200, 400, 800, 1600, 3200, 6400, 12800]\n",
    "        n_features = 2\n",
    "        n_classes = 2\n",
    "        n_infected = [round((20/100)*n_nodes[i]) if (20/100)*n_nodes[i]>=1  else 1 for i in range(len(n_nodes))]\n",
    "        # Probability matrix for edges between communities\n",
    "        edge_prob_matrix = np.array([\n",
    "                                        [0.8, 0.2],\n",
    "                                        [0.3, 0.7]\n",
    "                                    ])\n",
    "        # Node feature means for each community\n",
    "        node_feature_means = np.array([\n",
    "                                        [2, 1], #, 0, 0, 0],\n",
    "                                        [1, 2] #, 0, 0, 0]\n",
    "                                    ])\n",
    "        \n",
    "        semillas = [123, 234, 345, 456, 567, 678, 789, 321, 654, 987]\n",
    "        \n",
    "        # Bien separadas las clases:\n",
    "        graphs1 = [generate_synthetic_graph_csbm(n_nodes[i], n_classes, n_features, edge_prob_matrix, node_feature_means, n_infected[i], semillas[i], 0, feature_cov_matrix=None) for i in range(n_graphs)]\n",
    "        for j in range(10):\n",
    "            filename = os.path.join(self.path, f'graph_Dir_NoBalanced_{n_infected[j]}a{n_nodes[j]}_clasesSep_0{j}_flattened.npz')\n",
    "            np.savez(filename, x=graphs1[j].x, a=graphs1[j].a, y=graphs1[j].y)\n",
    "\n",
    "        # Free memory\n",
    "        del graphs1\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "    def read(self):\n",
    "        # We must return a list of Graph objects\n",
    "        output = []\n",
    "\n",
    "        n_nodes = [25, 50, 100, 200, 400, 800, 1600, 3200, 6400, 12800]\n",
    "        n_infected = [round((20/100)*n_nodes[i]) if (20/100)*n_nodes[i]>=1  else 1 for i in range(len(n_nodes))]\n",
    "        \n",
    "        for j in range(10):\n",
    "            data1 = np.load(os.path.join(self.path, f'graph_Dir_NoBalanced_{n_infected[j]}a{n_nodes[j]}_clasesSep_0{j}_flattened.npz'), allow_pickle=True)\n",
    "            output.append(\n",
    "                Graph(x=data1['x'], a=data1['a'][()], y=data1['y']) # también puede ser a=data['a'].item()\n",
    "            )\n",
    "\n",
    "        return output\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset19 = synthetic_Dir_diffSize_NoBalanced_20percent_clasesSep_flattened()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caso 20: dirigido, diferentes tamaños, NO balanceado (20%), clases mezcladas, features aplanadas\n",
    "\n",
    "Grafos iguales a los del caso 10, salvo que las features están aplanadas a 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class synthetic_Dir_diffSize_NoBalanced_20percent_clasesMezcl_flattened(Dataset):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    @property\n",
    "    def path(self):\n",
    "        return os.path.join(DATASET_FOLDER, \"syntheticGraphs\", self.__class__.__name__)\n",
    "    \n",
    "    def download(self):\n",
    "        os.makedirs(self.path)\n",
    "        \n",
    "        def generate_synthetic_graph_csbm(n_nodes, n_communities, n_features, edge_prob_matrix, node_feature_means,\\\n",
    "                                  n_infected, semilla, indice, feature_cov_matrix=None):\n",
    "            # Assign nodes to communities\n",
    "            np.random.seed(semilla*(indice+1))\n",
    "            indices = [np.random.randint(0,n_nodes) for i in range(n_infected)]\n",
    "            communities = np.array([int(j in indices) for j in range(n_nodes)])\n",
    "\n",
    "            # Generate node features\n",
    "            if feature_cov_matrix is None:\n",
    "                feature_cov_matrix = np.eye(n_features)\n",
    "            features = np.zeros((n_nodes, n_features))\n",
    "            for k in range(n_communities):\n",
    "                nodes_in_community = np.where(communities == k)[0]\n",
    "                features[nodes_in_community] = np.random.multivariate_normal(node_feature_means[k], feature_cov_matrix,\\\n",
    "                                                                             len(nodes_in_community))\n",
    "\n",
    "            # Compute community membership probabilities based on node features\n",
    "            community_membership_probs = softmax(features @ node_feature_means.T, axis=1)\n",
    "\n",
    "            # Generate edges based on community membership probabilities\n",
    "            adjacency_matrix = np.zeros((n_nodes, n_nodes))\n",
    "            for i in range(n_nodes):\n",
    "                for j in range(n_nodes):\n",
    "                    if i == j:\n",
    "                        continue\n",
    "                    community_i = communities[i]\n",
    "                    community_j = communities[j]\n",
    "                    edge_prob = edge_prob_matrix[community_i, community_j] * community_membership_probs[i, community_j] * community_membership_probs[j, community_i]\n",
    "                    adjacency_matrix[i, j] = np.random.binomial(1, edge_prob)\n",
    "\n",
    "            labels = tf.keras.utils.to_categorical(communities)\n",
    "            adjacency_matrix = sparse.csr_matrix(adjacency_matrix)\n",
    "            return Graph(x=np.ones((n_nodes, n_features)), a=adjacency_matrix, y=labels)\n",
    "\n",
    "        \n",
    "        n_graphs = 10\n",
    "        n_nodes = [25, 50, 100, 200, 400, 800, 1600, 3200, 6400, 12800]\n",
    "        n_features = 2\n",
    "        n_classes = 2\n",
    "        n_infected = [round((20/100)*n_nodes[i]) if (20/100)*n_nodes[i]>=1  else 1 for i in range(len(n_nodes))]\n",
    "        # Probability matrix for edges between communities\n",
    "        edge_prob_matrix = np.array([\n",
    "                                    [0.5, 0.5],\n",
    "                                    [0.5, 0.5]\n",
    "                            ])\n",
    "        # Node feature means for each community\n",
    "        node_feature_means = np.array([\n",
    "                                        [1, 1], #, 0, 0, 0],\n",
    "                                        [1, 1] #, 0, 0, 0]\n",
    "                                    ])\n",
    "        \n",
    "        semillas = [123, 234, 345, 456, 567, 678, 789, 321, 654, 987]\n",
    "        \n",
    "        # Clases un poco más juntas:\n",
    "        graphs2 = [generate_synthetic_graph_csbm(n_nodes[i], n_classes, n_features, edge_prob_matrix, node_feature_means, n_infected[i], semillas[i], 1, feature_cov_matrix=None) for i in range(n_graphs)]\n",
    "        for j in range(10):\n",
    "            filename = os.path.join(self.path, f'graph_Dir_NoBalanced_{n_infected[j]}a{n_nodes[j]}_clasesMezcl_2{j}_flattened.npz')\n",
    "            np.savez(filename, x=graphs2[j].x, a=graphs2[j].a, y=graphs2[j].y)\n",
    "\n",
    "        # Free memory\n",
    "        del graphs2\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "    def read(self):\n",
    "        # We must return a list of Graph objects\n",
    "        output = []\n",
    "\n",
    "        n_nodes = [25, 50, 100, 200, 400, 800, 1600, 3200, 6400, 12800]\n",
    "        n_infected = [round((20/100)*n_nodes[i]) if (20/100)*n_nodes[i]>=1  else 1 for i in range(len(n_nodes))]\n",
    "        \n",
    "        for j in range(10):\n",
    "            data2 = np.load(os.path.join(self.path, f'graph_Dir_NoBalanced_{n_infected[j]}a{n_nodes[j]}_clasesMezcl_2{j}_flattened.npz'), allow_pickle=True)\n",
    "            output.append(\n",
    "                Graph(x=data2['x'], a=data2['a'][()], y=data2['y']) # también puede ser a=data['a'].item()\n",
    "            )\n",
    "\n",
    "        return output\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset20 = synthetic_Dir_diffSize_NoBalanced_20percent_clasesMezcl_flattened()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
